{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c325d9e",
   "metadata": {},
   "source": [
    "## 딥러닝\n",
    "### 인공신경망"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd10457d",
   "metadata": {},
   "source": [
    "#### Tensorflow\n",
    "- https://www.tensorflow.org/?hl=ko\n",
    "- 딥러닝 라이브러리 중 가장 유명\n",
    "- 구글 브레인팀에서 개발\n",
    "\n",
    "#### PyTorch\n",
    "- https://pytorch.org/\n",
    "- https://pytorch.kr/\n",
    "- 메타(페이스북)에서 개발한 딥러닝 라이브러리\n",
    "- GPU 사용이 매우 용이해서 빨리 처리 가능 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486b8ee0",
   "metadata": {},
   "source": [
    "#### MNIST 데이터\n",
    "- AI에서 많이 사용하는 데이터 셋 중 하나\n",
    "- 미국 국립표준기술연구소에서 배포하는 이미지데이터\n",
    "- 손글씨(0~9), 붓꽃데이터, 패션데이터, Cifar10(컬러이미지) 등 존재\n",
    "\n",
    "#### Fashion MNIST "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7ea3595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텐서플로 사용\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21f3c203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "29515/29515 [==============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26421880/26421880 [==============================] - 2s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "5148/5148 [==============================] - 0s 0s/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4422102/4422102 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# 패션 MNIST를 로드하면서 훈련세트와 테스트세트로 분리\n",
    "# sklearn train_test_split()와 변수 배치가 다름!\n",
    "(train_input, train_target), (test_input, test_target) = keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf802e6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 60000개 이미지데이터 ,넓이 28픽셀, 높이 28픽셀\n",
    "train_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959ec73b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 60000개의 이미지에 대한 분류값\n",
    "train_target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd07d30",
   "metadata": {},
   "source": [
    "### 이미지 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b94e993b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f02746ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한글로 Matplotlib 사용시 항상 필요\n",
    "from matplotlib import rcParams, font_manager, rc\n",
    "\n",
    "font_path = 'C:/Windows/Fonts/malgun.ttf'\n",
    "font = font_manager.FontProperties(fname=font_path).get_name()\n",
    "rc('font', family=font)\n",
    "rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "sns.set_theme(font='Malgun Gothic', rc={'axes.unicode_minus': False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f674b9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1300x200 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 10개 차트 그리기\n",
    "fig, axes = plt.subplots(1, 10, figsize =(13, 2))\n",
    "for i in range(10):\n",
    "    axes[i].imshow(train_input[i], cmap='gray_r')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.title('Fashion MNIST 훈련샘플')\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57696f1",
   "metadata": {},
   "source": [
    "- 이미지는 픽셀당 흑백은 1byte, 컬러는 3~4byte를 사용\n",
    "- 해상도가 커지면 이미지파일 사이즈가 기하급수적으로 증가\n",
    "- 28x28 정도로 제한"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "078e1056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9, 0, 0, 3, 0, 2, 7, 2, 5, 5]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 각 이미지의 분류 값 \n",
    "[train_target[i] for i in range(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96ecda7",
   "metadata": {},
   "source": [
    "|레이블|0|1|2|3|4|5|6|7|8|9|\n",
    "|:---|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\n",
    "|패션MIST|티셔츠|바지|스웨터|드레스|코트|샌달|셔츠|스티커즈|가방|앵클 부츠|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9fab432c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8),\n",
       " array([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000],\n",
       "       dtype=int64))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 60000개 데이터에서 각 레이블별 6000개씩 이미지가 존재\n",
    "np.unique(train_target, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6243861",
   "metadata": {},
   "source": [
    "#### 사이킷런 머신러닝, 로지스틱회귀로 아이템 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb02249b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사이킷런 모듈 로드\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split    # 이거 필요없음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79242e1d",
   "metadata": {},
   "source": [
    "##### 이미지처리\n",
    "- 28x28 2차원배열을 784 1차원 배열로 변경해줘야 함\n",
    "\n",
    "    <img src=\"../image/ml0009.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9034d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D이미지를 1D 벡터(1차원 배열)로 펼치기\n",
    "# train_input.shape\n",
    "train_input = train_input.reshape(-1,28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "92e5398b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "314623de",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = test_input.reshape(-1, 28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "71bbad3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "92f74c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케일링(정규화)\n",
    "scaler = StandardScaler()\n",
    "train_scaled = scaler.fit_transform(train_input.astype(np.float64))\n",
    "test_scaled = scaler.transform(test_input.astype(np.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "67c21f1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=20, max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link \">i<span>Not fitted</span></span></div></label><div class=\"sk-toggleable__content \"><pre>LogisticRegression(C=20, max_iter=1000)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=20, max_iter=1000)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 로지스틱 회귀 모델\n",
    "lr = LogisticRegression(C=20, max_iter=1000)\n",
    "lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a739b30c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Source\\IoT-dataanalysis-2025\\mlvenv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=20, max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(C=20, max_iter=1000)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=20, max_iter=1000)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 훈련\n",
    "lr.fit(train_scaled, train_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66f0c64",
   "metadata": {},
   "source": [
    "- 60000만건 훈련시 대략 2분 42초 소요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a4478563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8305"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정확도\n",
    "lr.score(test_scaled, test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1e9c09f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측\n",
    "pred_result = lr.predict(test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "66df2b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트이미지와 예측 결과 시각화\n",
    "def show_image(index):\n",
    "    plt.figure(figsize=(10, 2))\n",
    "    plt.imshow(test_input[index].reshape(28,28), cmap='gray_r')\n",
    "    plt.title(f'실제: {test_target[index]}, 예측: {pred_result[index]}')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "58ec00ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(11,17):\n",
    "    show_image(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfb19df",
   "metadata": {},
   "source": [
    "- 여기까지 머신러닝으로 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d8b0ed",
   "metadata": {},
   "source": [
    "#### 인공신경망\n",
    "\n",
    "- 인간의 뇌 속 뉴런과 유사한 구조로 만든 것\n",
    "- 인공신경망을 이용해서 머신러닝 훈련과 테스트, 예측등을 수행하는 것\n",
    "- 인공지능 ⊃ 머신러닝 ⊃ 딥러닝(인공신경망)\n",
    "- 정확도가 높아서 딥러닝 가장 많이 사용 - 트렌드\n",
    "\n",
    "<img src=\"../image/ml0010.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0541d2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텐서플로 모듈 로드\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c7c1fcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3a4e95f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_split() 함수로 기존 훈련세트를 훈련세트:검증세트 8:2로 분리\n",
    "train_scaled, val_scaled, train_target, val_target = train_test_split(\n",
    "    train_scaled, train_target, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a6e22fcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38400, 784)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_scaled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3d41ab",
   "metadata": {},
   "source": [
    "- 기존 훈련세트 -> 60000\n",
    "- 새 훈련세트 -> 48000\n",
    "- 검증세트 -> 12000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea191db",
   "metadata": {},
   "source": [
    "- 밀집층(Dense layer)\n",
    "    - 784 픽셀(28*28)을 10개(분류된 아이템 개수) 뉴런 연결하면 7840개 연결선이 만들어짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0b6f51a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Source\\IoT-dataanalysis-2025\\mlvenv\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 매개변수\n",
    "## 10 출력값(아이템 0~9)\n",
    "## activation 활성화 함수 : softmax, figmod, ReLU ...\n",
    "## 입력크기 : 28*28\n",
    "dense = keras.layers.Dense(10, activation='softmax', input_shape=(784,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fc7c2c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6aba3418",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', metrics='accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "32935fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1200/1200 [==============================] - 1s 856us/step - loss: 0.4071 - accuracy: 0.8660\n",
      "Epoch 2/1000\n",
      "1200/1200 [==============================] - 1s 830us/step - loss: 0.4090 - accuracy: 0.8664\n",
      "Epoch 3/1000\n",
      "1200/1200 [==============================] - 1s 822us/step - loss: 0.4065 - accuracy: 0.8658\n",
      "Epoch 4/1000\n",
      "1200/1200 [==============================] - 1s 809us/step - loss: 0.4053 - accuracy: 0.8672\n",
      "Epoch 5/1000\n",
      "1200/1200 [==============================] - 1s 800us/step - loss: 0.4066 - accuracy: 0.8671\n",
      "Epoch 6/1000\n",
      "1200/1200 [==============================] - 1s 804us/step - loss: 0.4063 - accuracy: 0.8681\n",
      "Epoch 7/1000\n",
      "1200/1200 [==============================] - 1s 826us/step - loss: 0.4050 - accuracy: 0.8676\n",
      "Epoch 8/1000\n",
      "1200/1200 [==============================] - 1s 813us/step - loss: 0.4032 - accuracy: 0.8694\n",
      "Epoch 9/1000\n",
      "1200/1200 [==============================] - 1s 824us/step - loss: 0.4034 - accuracy: 0.8703\n",
      "Epoch 10/1000\n",
      "1200/1200 [==============================] - 1s 821us/step - loss: 0.4038 - accuracy: 0.8696\n",
      "Epoch 11/1000\n",
      "1200/1200 [==============================] - 1s 825us/step - loss: 0.4046 - accuracy: 0.8692\n",
      "Epoch 12/1000\n",
      "1200/1200 [==============================] - 1s 870us/step - loss: 0.4020 - accuracy: 0.8671\n",
      "Epoch 13/1000\n",
      "1200/1200 [==============================] - 1s 823us/step - loss: 0.4026 - accuracy: 0.8697\n",
      "Epoch 14/1000\n",
      "1200/1200 [==============================] - 1s 807us/step - loss: 0.4038 - accuracy: 0.8696\n",
      "Epoch 15/1000\n",
      "1200/1200 [==============================] - 1s 809us/step - loss: 0.4015 - accuracy: 0.8710\n",
      "Epoch 16/1000\n",
      "1200/1200 [==============================] - 1s 824us/step - loss: 0.4033 - accuracy: 0.8699\n",
      "Epoch 17/1000\n",
      "1200/1200 [==============================] - 1s 854us/step - loss: 0.4029 - accuracy: 0.8698\n",
      "Epoch 18/1000\n",
      "1200/1200 [==============================] - 1s 874us/step - loss: 0.4014 - accuracy: 0.8708\n",
      "Epoch 19/1000\n",
      "1200/1200 [==============================] - 1s 859us/step - loss: 0.4015 - accuracy: 0.8707\n",
      "Epoch 20/1000\n",
      "1200/1200 [==============================] - 1s 893us/step - loss: 0.4000 - accuracy: 0.8721\n",
      "Epoch 21/1000\n",
      "1200/1200 [==============================] - 1s 861us/step - loss: 0.4002 - accuracy: 0.8711\n",
      "Epoch 22/1000\n",
      "1200/1200 [==============================] - 1s 863us/step - loss: 0.4008 - accuracy: 0.8694\n",
      "Epoch 23/1000\n",
      "1200/1200 [==============================] - 1s 864us/step - loss: 0.4002 - accuracy: 0.8708\n",
      "Epoch 24/1000\n",
      "1200/1200 [==============================] - 1s 860us/step - loss: 0.4003 - accuracy: 0.8713\n",
      "Epoch 25/1000\n",
      "1200/1200 [==============================] - 1s 852us/step - loss: 0.3986 - accuracy: 0.8713\n",
      "Epoch 26/1000\n",
      "1200/1200 [==============================] - 1s 903us/step - loss: 0.3992 - accuracy: 0.8707\n",
      "Epoch 27/1000\n",
      "1200/1200 [==============================] - 1s 880us/step - loss: 0.3985 - accuracy: 0.8729\n",
      "Epoch 28/1000\n",
      "1200/1200 [==============================] - 1s 872us/step - loss: 0.3997 - accuracy: 0.8716\n",
      "Epoch 29/1000\n",
      "1200/1200 [==============================] - 1s 853us/step - loss: 0.4003 - accuracy: 0.8699\n",
      "Epoch 30/1000\n",
      "1200/1200 [==============================] - 1s 878us/step - loss: 0.3994 - accuracy: 0.8722\n",
      "Epoch 31/1000\n",
      "1200/1200 [==============================] - 1s 866us/step - loss: 0.3986 - accuracy: 0.8711\n",
      "Epoch 32/1000\n",
      "1200/1200 [==============================] - 1s 854us/step - loss: 0.3979 - accuracy: 0.8721\n",
      "Epoch 33/1000\n",
      "1200/1200 [==============================] - 1s 849us/step - loss: 0.3990 - accuracy: 0.8707\n",
      "Epoch 34/1000\n",
      "1200/1200 [==============================] - 1s 851us/step - loss: 0.3978 - accuracy: 0.8719\n",
      "Epoch 35/1000\n",
      "1200/1200 [==============================] - 1s 901us/step - loss: 0.3994 - accuracy: 0.8727\n",
      "Epoch 36/1000\n",
      "1200/1200 [==============================] - 1s 853us/step - loss: 0.3990 - accuracy: 0.8714\n",
      "Epoch 37/1000\n",
      "1200/1200 [==============================] - 1s 869us/step - loss: 0.3983 - accuracy: 0.8732\n",
      "Epoch 38/1000\n",
      "1200/1200 [==============================] - 1s 884us/step - loss: 0.3975 - accuracy: 0.8720\n",
      "Epoch 39/1000\n",
      "1200/1200 [==============================] - 1s 904us/step - loss: 0.3976 - accuracy: 0.8714\n",
      "Epoch 40/1000\n",
      "1200/1200 [==============================] - 1s 882us/step - loss: 0.3990 - accuracy: 0.8719\n",
      "Epoch 41/1000\n",
      "1200/1200 [==============================] - 1s 898us/step - loss: 0.3972 - accuracy: 0.8703\n",
      "Epoch 42/1000\n",
      "1200/1200 [==============================] - 1s 886us/step - loss: 0.3971 - accuracy: 0.8725\n",
      "Epoch 43/1000\n",
      "1200/1200 [==============================] - 1s 865us/step - loss: 0.3974 - accuracy: 0.8736\n",
      "Epoch 44/1000\n",
      "1200/1200 [==============================] - 1s 806us/step - loss: 0.3961 - accuracy: 0.8731\n",
      "Epoch 45/1000\n",
      "1200/1200 [==============================] - 1s 808us/step - loss: 0.3979 - accuracy: 0.8718\n",
      "Epoch 46/1000\n",
      "1200/1200 [==============================] - 1s 815us/step - loss: 0.3965 - accuracy: 0.8713\n",
      "Epoch 47/1000\n",
      "1200/1200 [==============================] - 1s 835us/step - loss: 0.3984 - accuracy: 0.8718\n",
      "Epoch 48/1000\n",
      "1200/1200 [==============================] - 1s 826us/step - loss: 0.3963 - accuracy: 0.8719\n",
      "Epoch 49/1000\n",
      "1200/1200 [==============================] - 1s 830us/step - loss: 0.3958 - accuracy: 0.8734\n",
      "Epoch 50/1000\n",
      "1200/1200 [==============================] - 1s 871us/step - loss: 0.3956 - accuracy: 0.8712\n",
      "Epoch 51/1000\n",
      "1200/1200 [==============================] - 1s 822us/step - loss: 0.3952 - accuracy: 0.8736\n",
      "Epoch 52/1000\n",
      "1200/1200 [==============================] - 1s 856us/step - loss: 0.3943 - accuracy: 0.8746\n",
      "Epoch 53/1000\n",
      "1200/1200 [==============================] - 1s 840us/step - loss: 0.3963 - accuracy: 0.8729\n",
      "Epoch 54/1000\n",
      "1200/1200 [==============================] - 1s 839us/step - loss: 0.3961 - accuracy: 0.8730\n",
      "Epoch 55/1000\n",
      "1200/1200 [==============================] - 1s 829us/step - loss: 0.3943 - accuracy: 0.8743\n",
      "Epoch 56/1000\n",
      "1200/1200 [==============================] - 1s 847us/step - loss: 0.3953 - accuracy: 0.8733\n",
      "Epoch 57/1000\n",
      "1200/1200 [==============================] - 1s 813us/step - loss: 0.3953 - accuracy: 0.8737\n",
      "Epoch 58/1000\n",
      "1200/1200 [==============================] - 1s 850us/step - loss: 0.3937 - accuracy: 0.8755\n",
      "Epoch 59/1000\n",
      "1200/1200 [==============================] - 1s 836us/step - loss: 0.3965 - accuracy: 0.8733\n",
      "Epoch 60/1000\n",
      "1200/1200 [==============================] - 1s 839us/step - loss: 0.3953 - accuracy: 0.8749\n",
      "Epoch 61/1000\n",
      "1200/1200 [==============================] - 1s 847us/step - loss: 0.3967 - accuracy: 0.8739\n",
      "Epoch 62/1000\n",
      "1200/1200 [==============================] - 1s 841us/step - loss: 0.3951 - accuracy: 0.8718\n",
      "Epoch 63/1000\n",
      "1200/1200 [==============================] - 1s 833us/step - loss: 0.3945 - accuracy: 0.8743\n",
      "Epoch 64/1000\n",
      "1200/1200 [==============================] - 1s 827us/step - loss: 0.3964 - accuracy: 0.8747\n",
      "Epoch 65/1000\n",
      "1200/1200 [==============================] - 1s 876us/step - loss: 0.3950 - accuracy: 0.8741\n",
      "Epoch 66/1000\n",
      "1200/1200 [==============================] - 1s 841us/step - loss: 0.3963 - accuracy: 0.8740\n",
      "Epoch 67/1000\n",
      "1200/1200 [==============================] - 1s 845us/step - loss: 0.3950 - accuracy: 0.8737\n",
      "Epoch 68/1000\n",
      "1200/1200 [==============================] - 1s 844us/step - loss: 0.3960 - accuracy: 0.8743\n",
      "Epoch 69/1000\n",
      "1200/1200 [==============================] - 1s 841us/step - loss: 0.3952 - accuracy: 0.8754\n",
      "Epoch 70/1000\n",
      "1200/1200 [==============================] - 1s 804us/step - loss: 0.3931 - accuracy: 0.8743\n",
      "Epoch 71/1000\n",
      "1200/1200 [==============================] - 1s 818us/step - loss: 0.3954 - accuracy: 0.8731\n",
      "Epoch 72/1000\n",
      "1200/1200 [==============================] - 1s 801us/step - loss: 0.3950 - accuracy: 0.8741\n",
      "Epoch 73/1000\n",
      "1200/1200 [==============================] - 1s 823us/step - loss: 0.3944 - accuracy: 0.8735\n",
      "Epoch 74/1000\n",
      "1200/1200 [==============================] - 1s 817us/step - loss: 0.3948 - accuracy: 0.8737\n",
      "Epoch 75/1000\n",
      "1200/1200 [==============================] - 1s 812us/step - loss: 0.3945 - accuracy: 0.8740\n",
      "Epoch 76/1000\n",
      "1200/1200 [==============================] - 1s 821us/step - loss: 0.3953 - accuracy: 0.8735\n",
      "Epoch 77/1000\n",
      "1200/1200 [==============================] - 1s 817us/step - loss: 0.3942 - accuracy: 0.8744\n",
      "Epoch 78/1000\n",
      "1200/1200 [==============================] - 1s 811us/step - loss: 0.3926 - accuracy: 0.8745\n",
      "Epoch 79/1000\n",
      "1200/1200 [==============================] - 1s 807us/step - loss: 0.3928 - accuracy: 0.8758\n",
      "Epoch 80/1000\n",
      "1200/1200 [==============================] - 1s 872us/step - loss: 0.3928 - accuracy: 0.8753\n",
      "Epoch 81/1000\n",
      "1200/1200 [==============================] - 1s 815us/step - loss: 0.3918 - accuracy: 0.8741\n",
      "Epoch 82/1000\n",
      "1200/1200 [==============================] - 1s 822us/step - loss: 0.3927 - accuracy: 0.8748\n",
      "Epoch 83/1000\n",
      "1200/1200 [==============================] - 1s 823us/step - loss: 0.3921 - accuracy: 0.8744\n",
      "Epoch 84/1000\n",
      "1200/1200 [==============================] - 1s 794us/step - loss: 0.3933 - accuracy: 0.8742\n",
      "Epoch 85/1000\n",
      "1200/1200 [==============================] - 1s 811us/step - loss: 0.3936 - accuracy: 0.8763\n",
      "Epoch 86/1000\n",
      "1200/1200 [==============================] - 1s 792us/step - loss: 0.3953 - accuracy: 0.8737\n",
      "Epoch 87/1000\n",
      "1200/1200 [==============================] - 1s 811us/step - loss: 0.3932 - accuracy: 0.8744\n",
      "Epoch 88/1000\n",
      "1200/1200 [==============================] - 1s 800us/step - loss: 0.3943 - accuracy: 0.8728\n",
      "Epoch 89/1000\n",
      "1200/1200 [==============================] - 1s 817us/step - loss: 0.3952 - accuracy: 0.8735\n",
      "Epoch 90/1000\n",
      "1200/1200 [==============================] - 1s 827us/step - loss: 0.3950 - accuracy: 0.8760\n",
      "Epoch 91/1000\n",
      "1200/1200 [==============================] - 1s 800us/step - loss: 0.3933 - accuracy: 0.8739\n",
      "Epoch 92/1000\n",
      "1200/1200 [==============================] - 1s 826us/step - loss: 0.3956 - accuracy: 0.8747\n",
      "Epoch 93/1000\n",
      "1200/1200 [==============================] - 1s 811us/step - loss: 0.3932 - accuracy: 0.8755\n",
      "Epoch 94/1000\n",
      "1200/1200 [==============================] - 1s 817us/step - loss: 0.3953 - accuracy: 0.8752\n",
      "Epoch 95/1000\n",
      "1200/1200 [==============================] - 1s 811us/step - loss: 0.3938 - accuracy: 0.8745\n",
      "Epoch 96/1000\n",
      "1200/1200 [==============================] - 1s 858us/step - loss: 0.3944 - accuracy: 0.8746\n",
      "Epoch 97/1000\n",
      "1200/1200 [==============================] - 1s 817us/step - loss: 0.3934 - accuracy: 0.8758\n",
      "Epoch 98/1000\n",
      "1200/1200 [==============================] - 1s 838us/step - loss: 0.3928 - accuracy: 0.8759\n",
      "Epoch 99/1000\n",
      "1200/1200 [==============================] - 1s 838us/step - loss: 0.3950 - accuracy: 0.8754\n",
      "Epoch 100/1000\n",
      "1200/1200 [==============================] - 1s 836us/step - loss: 0.3925 - accuracy: 0.8748\n",
      "Epoch 101/1000\n",
      "1200/1200 [==============================] - 1s 856us/step - loss: 0.3934 - accuracy: 0.8757\n",
      "Epoch 102/1000\n",
      "1200/1200 [==============================] - 1s 855us/step - loss: 0.3927 - accuracy: 0.8768\n",
      "Epoch 103/1000\n",
      "1200/1200 [==============================] - 1s 850us/step - loss: 0.3921 - accuracy: 0.8752\n",
      "Epoch 104/1000\n",
      "1200/1200 [==============================] - 1s 876us/step - loss: 0.3941 - accuracy: 0.8742\n",
      "Epoch 105/1000\n",
      "1200/1200 [==============================] - 1s 827us/step - loss: 0.3932 - accuracy: 0.8745\n",
      "Epoch 106/1000\n",
      "1200/1200 [==============================] - 1s 829us/step - loss: 0.3939 - accuracy: 0.8746\n",
      "Epoch 107/1000\n",
      "1200/1200 [==============================] - 1s 845us/step - loss: 0.3943 - accuracy: 0.8749\n",
      "Epoch 108/1000\n",
      "1200/1200 [==============================] - 1s 833us/step - loss: 0.3945 - accuracy: 0.8750\n",
      "Epoch 109/1000\n",
      "1200/1200 [==============================] - 1s 828us/step - loss: 0.3935 - accuracy: 0.8754\n",
      "Epoch 110/1000\n",
      "1200/1200 [==============================] - 1s 828us/step - loss: 0.3941 - accuracy: 0.8752\n",
      "Epoch 111/1000\n",
      "1200/1200 [==============================] - 1s 813us/step - loss: 0.3915 - accuracy: 0.8752\n",
      "Epoch 112/1000\n",
      "1200/1200 [==============================] - 1s 816us/step - loss: 0.3931 - accuracy: 0.8770\n",
      "Epoch 113/1000\n",
      "1200/1200 [==============================] - 1s 816us/step - loss: 0.3928 - accuracy: 0.8769\n",
      "Epoch 114/1000\n",
      "1200/1200 [==============================] - 1s 826us/step - loss: 0.3920 - accuracy: 0.8757\n",
      "Epoch 115/1000\n",
      "1200/1200 [==============================] - 1s 803us/step - loss: 0.3932 - accuracy: 0.8755\n",
      "Epoch 116/1000\n",
      "1200/1200 [==============================] - 1s 815us/step - loss: 0.3921 - accuracy: 0.8751\n",
      "Epoch 117/1000\n",
      "1200/1200 [==============================] - 1s 802us/step - loss: 0.3925 - accuracy: 0.8761\n",
      "Epoch 118/1000\n",
      "1200/1200 [==============================] - 1s 839us/step - loss: 0.3935 - accuracy: 0.8751\n",
      "Epoch 119/1000\n",
      "1200/1200 [==============================] - 1s 803us/step - loss: 0.3926 - accuracy: 0.8757\n",
      "Epoch 120/1000\n",
      "1200/1200 [==============================] - 1s 811us/step - loss: 0.3924 - accuracy: 0.8741\n",
      "Epoch 121/1000\n",
      "1200/1200 [==============================] - 1s 807us/step - loss: 0.3934 - accuracy: 0.8746\n",
      "Epoch 122/1000\n",
      "1200/1200 [==============================] - 1s 807us/step - loss: 0.3923 - accuracy: 0.8764\n",
      "Epoch 123/1000\n",
      "1200/1200 [==============================] - 1s 812us/step - loss: 0.3924 - accuracy: 0.8755\n",
      "Epoch 124/1000\n",
      "1200/1200 [==============================] - 1s 828us/step - loss: 0.3936 - accuracy: 0.8752\n",
      "Epoch 125/1000\n",
      "1200/1200 [==============================] - 1s 822us/step - loss: 0.3935 - accuracy: 0.8758\n",
      "Epoch 126/1000\n",
      "1200/1200 [==============================] - 1s 807us/step - loss: 0.3927 - accuracy: 0.8769\n",
      "Epoch 127/1000\n",
      "1200/1200 [==============================] - 1s 818us/step - loss: 0.3925 - accuracy: 0.8746\n",
      "Epoch 128/1000\n",
      "1200/1200 [==============================] - 1s 804us/step - loss: 0.3951 - accuracy: 0.8761\n",
      "Epoch 129/1000\n",
      "1200/1200 [==============================] - 1s 817us/step - loss: 0.3939 - accuracy: 0.8758\n",
      "Epoch 130/1000\n",
      "1200/1200 [==============================] - 1s 810us/step - loss: 0.3928 - accuracy: 0.8772\n",
      "Epoch 131/1000\n",
      "1200/1200 [==============================] - 1s 851us/step - loss: 0.3928 - accuracy: 0.8759\n",
      "Epoch 132/1000\n",
      "1200/1200 [==============================] - 1s 809us/step - loss: 0.3929 - accuracy: 0.8754\n",
      "Epoch 133/1000\n",
      "1200/1200 [==============================] - 1s 812us/step - loss: 0.3926 - accuracy: 0.8768\n",
      "Epoch 134/1000\n",
      "1200/1200 [==============================] - 1s 817us/step - loss: 0.3921 - accuracy: 0.8762\n",
      "Epoch 135/1000\n",
      "1200/1200 [==============================] - 1s 803us/step - loss: 0.3934 - accuracy: 0.8755\n",
      "Epoch 136/1000\n",
      "1200/1200 [==============================] - 1s 853us/step - loss: 0.3932 - accuracy: 0.8737\n",
      "Epoch 137/1000\n",
      "1200/1200 [==============================] - 1s 913us/step - loss: 0.3937 - accuracy: 0.8753\n",
      "Epoch 138/1000\n",
      "1200/1200 [==============================] - 1s 931us/step - loss: 0.3923 - accuracy: 0.8763\n",
      "Epoch 139/1000\n",
      "1200/1200 [==============================] - 1s 822us/step - loss: 0.3925 - accuracy: 0.8765\n",
      "Epoch 140/1000\n",
      "1200/1200 [==============================] - 1s 839us/step - loss: 0.3925 - accuracy: 0.8763\n",
      "Epoch 141/1000\n",
      "1200/1200 [==============================] - 1s 806us/step - loss: 0.3942 - accuracy: 0.8753\n",
      "Epoch 142/1000\n",
      "1200/1200 [==============================] - 1s 824us/step - loss: 0.3933 - accuracy: 0.8751\n",
      "Epoch 143/1000\n",
      "1200/1200 [==============================] - 1s 810us/step - loss: 0.3939 - accuracy: 0.8765\n",
      "Epoch 144/1000\n",
      "1200/1200 [==============================] - 1s 805us/step - loss: 0.3941 - accuracy: 0.8759\n",
      "Epoch 145/1000\n",
      "1200/1200 [==============================] - 1s 814us/step - loss: 0.3948 - accuracy: 0.8760\n",
      "Epoch 146/1000\n",
      "1200/1200 [==============================] - 1s 810us/step - loss: 0.3940 - accuracy: 0.8753\n",
      "Epoch 147/1000\n",
      "1200/1200 [==============================] - 1s 819us/step - loss: 0.3921 - accuracy: 0.8764\n",
      "Epoch 148/1000\n",
      "1200/1200 [==============================] - 1s 808us/step - loss: 0.3936 - accuracy: 0.8761\n",
      "Epoch 149/1000\n",
      "1200/1200 [==============================] - 1s 846us/step - loss: 0.3932 - accuracy: 0.8763\n",
      "Epoch 150/1000\n",
      "1200/1200 [==============================] - 1s 823us/step - loss: 0.3924 - accuracy: 0.8766\n",
      "Epoch 151/1000\n",
      "1200/1200 [==============================] - 1s 837us/step - loss: 0.3934 - accuracy: 0.8781\n",
      "Epoch 152/1000\n",
      "1200/1200 [==============================] - 1s 813us/step - loss: 0.3942 - accuracy: 0.8754\n",
      "Epoch 153/1000\n",
      "1200/1200 [==============================] - 1s 812us/step - loss: 0.3936 - accuracy: 0.8763\n",
      "Epoch 154/1000\n",
      "1200/1200 [==============================] - 1s 816us/step - loss: 0.3937 - accuracy: 0.8769\n",
      "Epoch 155/1000\n",
      "1200/1200 [==============================] - 1s 827us/step - loss: 0.3936 - accuracy: 0.8754\n",
      "Epoch 156/1000\n",
      "1200/1200 [==============================] - 1s 815us/step - loss: 0.3935 - accuracy: 0.8750\n",
      "Epoch 157/1000\n",
      "1200/1200 [==============================] - 1s 815us/step - loss: 0.3926 - accuracy: 0.8760\n",
      "Epoch 158/1000\n",
      "1200/1200 [==============================] - 1s 822us/step - loss: 0.3933 - accuracy: 0.8753\n",
      "Epoch 159/1000\n",
      "1200/1200 [==============================] - 1s 801us/step - loss: 0.3938 - accuracy: 0.8767\n",
      "Epoch 160/1000\n",
      "1200/1200 [==============================] - 1s 821us/step - loss: 0.3935 - accuracy: 0.8763\n",
      "Epoch 161/1000\n",
      "1200/1200 [==============================] - 1s 835us/step - loss: 0.3941 - accuracy: 0.8766\n",
      "Epoch 162/1000\n",
      "1200/1200 [==============================] - 1s 824us/step - loss: 0.3914 - accuracy: 0.8764\n",
      "Epoch 163/1000\n",
      "1200/1200 [==============================] - 1s 814us/step - loss: 0.3942 - accuracy: 0.8754\n",
      "Epoch 164/1000\n",
      "1200/1200 [==============================] - 1s 839us/step - loss: 0.3950 - accuracy: 0.8777\n",
      "Epoch 165/1000\n",
      "1200/1200 [==============================] - 1s 854us/step - loss: 0.3943 - accuracy: 0.8764\n",
      "Epoch 166/1000\n",
      "1200/1200 [==============================] - 1s 848us/step - loss: 0.3921 - accuracy: 0.8768\n",
      "Epoch 167/1000\n",
      "1200/1200 [==============================] - 1s 837us/step - loss: 0.3931 - accuracy: 0.8766\n",
      "Epoch 168/1000\n",
      "1200/1200 [==============================] - 1s 804us/step - loss: 0.3933 - accuracy: 0.8765\n",
      "Epoch 169/1000\n",
      "1200/1200 [==============================] - 1s 812us/step - loss: 0.3933 - accuracy: 0.8751\n",
      "Epoch 170/1000\n",
      "1200/1200 [==============================] - 1s 815us/step - loss: 0.3931 - accuracy: 0.8756\n",
      "Epoch 171/1000\n",
      "1200/1200 [==============================] - 1s 813us/step - loss: 0.3930 - accuracy: 0.8763\n",
      "Epoch 172/1000\n",
      "1200/1200 [==============================] - 1s 810us/step - loss: 0.3931 - accuracy: 0.8768\n",
      "Epoch 173/1000\n",
      "1200/1200 [==============================] - 1s 826us/step - loss: 0.3935 - accuracy: 0.8751\n",
      "Epoch 174/1000\n",
      "1200/1200 [==============================] - 1s 811us/step - loss: 0.3934 - accuracy: 0.8759\n",
      "Epoch 175/1000\n",
      "1200/1200 [==============================] - 1s 810us/step - loss: 0.3931 - accuracy: 0.8771\n",
      "Epoch 176/1000\n",
      "1200/1200 [==============================] - 1s 843us/step - loss: 0.3919 - accuracy: 0.8768\n",
      "Epoch 177/1000\n",
      "1200/1200 [==============================] - 1s 833us/step - loss: 0.3924 - accuracy: 0.8779\n",
      "Epoch 178/1000\n",
      "1200/1200 [==============================] - 1s 858us/step - loss: 0.3927 - accuracy: 0.8765\n",
      "Epoch 179/1000\n",
      "1200/1200 [==============================] - 1s 829us/step - loss: 0.3926 - accuracy: 0.8769\n",
      "Epoch 180/1000\n",
      "1200/1200 [==============================] - 1s 833us/step - loss: 0.3914 - accuracy: 0.8778\n",
      "Epoch 181/1000\n",
      "1200/1200 [==============================] - 1s 830us/step - loss: 0.3950 - accuracy: 0.8755\n",
      "Epoch 182/1000\n",
      "1200/1200 [==============================] - 1s 830us/step - loss: 0.3931 - accuracy: 0.8764\n",
      "Epoch 183/1000\n",
      "1200/1200 [==============================] - 1s 840us/step - loss: 0.3926 - accuracy: 0.8761\n",
      "Epoch 184/1000\n",
      "1200/1200 [==============================] - 1s 849us/step - loss: 0.3939 - accuracy: 0.8755\n",
      "Epoch 185/1000\n",
      "1200/1200 [==============================] - 1s 826us/step - loss: 0.3918 - accuracy: 0.8774\n",
      "Epoch 186/1000\n",
      "1200/1200 [==============================] - 1s 836us/step - loss: 0.3930 - accuracy: 0.8762\n",
      "Epoch 187/1000\n",
      "1200/1200 [==============================] - 1s 827us/step - loss: 0.3925 - accuracy: 0.8770\n",
      "Epoch 188/1000\n",
      "1200/1200 [==============================] - 1s 817us/step - loss: 0.3928 - accuracy: 0.8759\n",
      "Epoch 189/1000\n",
      "1200/1200 [==============================] - 1s 847us/step - loss: 0.3926 - accuracy: 0.8770\n",
      "Epoch 190/1000\n",
      "1200/1200 [==============================] - 1s 815us/step - loss: 0.3938 - accuracy: 0.8764\n",
      "Epoch 191/1000\n",
      "1200/1200 [==============================] - 1s 840us/step - loss: 0.3912 - accuracy: 0.8758\n",
      "Epoch 192/1000\n",
      "1200/1200 [==============================] - 1s 830us/step - loss: 0.3918 - accuracy: 0.8772\n",
      "Epoch 193/1000\n",
      "1200/1200 [==============================] - 1s 821us/step - loss: 0.3940 - accuracy: 0.8775\n",
      "Epoch 194/1000\n",
      "1200/1200 [==============================] - 1s 854us/step - loss: 0.3924 - accuracy: 0.8760\n",
      "Epoch 195/1000\n",
      "1200/1200 [==============================] - 1s 854us/step - loss: 0.3931 - accuracy: 0.8759\n",
      "Epoch 196/1000\n",
      "1200/1200 [==============================] - 1s 840us/step - loss: 0.3930 - accuracy: 0.8770\n",
      "Epoch 197/1000\n",
      "1200/1200 [==============================] - 1s 833us/step - loss: 0.3934 - accuracy: 0.8763\n",
      "Epoch 198/1000\n",
      "1200/1200 [==============================] - 1s 840us/step - loss: 0.3917 - accuracy: 0.8759\n",
      "Epoch 199/1000\n",
      "1200/1200 [==============================] - 1s 829us/step - loss: 0.3930 - accuracy: 0.8773\n",
      "Epoch 200/1000\n",
      "1200/1200 [==============================] - 1s 855us/step - loss: 0.3943 - accuracy: 0.8767\n",
      "Epoch 201/1000\n",
      "1200/1200 [==============================] - 1s 811us/step - loss: 0.3947 - accuracy: 0.8768\n",
      "Epoch 202/1000\n",
      "1200/1200 [==============================] - 1s 820us/step - loss: 0.3920 - accuracy: 0.8760\n",
      "Epoch 203/1000\n",
      "1200/1200 [==============================] - 1s 812us/step - loss: 0.3925 - accuracy: 0.8754\n",
      "Epoch 204/1000\n",
      "1200/1200 [==============================] - 1s 822us/step - loss: 0.3924 - accuracy: 0.8762\n",
      "Epoch 205/1000\n",
      "1200/1200 [==============================] - 1s 831us/step - loss: 0.3919 - accuracy: 0.8771\n",
      "Epoch 206/1000\n",
      "1200/1200 [==============================] - 1s 813us/step - loss: 0.3918 - accuracy: 0.8768\n",
      "Epoch 207/1000\n",
      "1200/1200 [==============================] - 1s 819us/step - loss: 0.3926 - accuracy: 0.8773\n",
      "Epoch 208/1000\n",
      "1200/1200 [==============================] - 1s 814us/step - loss: 0.3935 - accuracy: 0.8762\n",
      "Epoch 209/1000\n",
      "1200/1200 [==============================] - 1s 823us/step - loss: 0.3936 - accuracy: 0.8766\n",
      "Epoch 210/1000\n",
      "1200/1200 [==============================] - 1s 833us/step - loss: 0.3943 - accuracy: 0.8772\n",
      "Epoch 211/1000\n",
      "1200/1200 [==============================] - 1s 827us/step - loss: 0.3934 - accuracy: 0.8778\n",
      "Epoch 212/1000\n",
      "1200/1200 [==============================] - 1s 814us/step - loss: 0.3929 - accuracy: 0.8773\n",
      "Epoch 213/1000\n",
      "1200/1200 [==============================] - 1s 818us/step - loss: 0.3956 - accuracy: 0.8766\n",
      "Epoch 214/1000\n",
      "1200/1200 [==============================] - 1s 806us/step - loss: 0.3918 - accuracy: 0.8767\n",
      "Epoch 215/1000\n",
      "1200/1200 [==============================] - 1s 832us/step - loss: 0.3943 - accuracy: 0.8768\n",
      "Epoch 216/1000\n",
      "1200/1200 [==============================] - 1s 813us/step - loss: 0.3934 - accuracy: 0.8760\n",
      "Epoch 217/1000\n",
      "1200/1200 [==============================] - 1s 814us/step - loss: 0.3931 - accuracy: 0.8767\n",
      "Epoch 218/1000\n",
      "1200/1200 [==============================] - 1s 810us/step - loss: 0.3949 - accuracy: 0.8773\n",
      "Epoch 219/1000\n",
      "1200/1200 [==============================] - 1s 811us/step - loss: 0.3937 - accuracy: 0.8764\n",
      "Epoch 220/1000\n",
      "1200/1200 [==============================] - 1s 831us/step - loss: 0.3930 - accuracy: 0.8766\n",
      "Epoch 221/1000\n",
      "1200/1200 [==============================] - 1s 798us/step - loss: 0.3930 - accuracy: 0.8780\n",
      "Epoch 222/1000\n",
      "1200/1200 [==============================] - 1s 835us/step - loss: 0.3939 - accuracy: 0.8766\n",
      "Epoch 223/1000\n",
      "1200/1200 [==============================] - 1s 813us/step - loss: 0.3946 - accuracy: 0.8771\n",
      "Epoch 224/1000\n",
      "1200/1200 [==============================] - 1s 843us/step - loss: 0.3946 - accuracy: 0.8754\n",
      "Epoch 225/1000\n",
      "1200/1200 [==============================] - 1s 854us/step - loss: 0.3930 - accuracy: 0.8782\n",
      "Epoch 226/1000\n",
      "1200/1200 [==============================] - 1s 847us/step - loss: 0.3942 - accuracy: 0.8779\n",
      "Epoch 227/1000\n",
      "1200/1200 [==============================] - 1s 834us/step - loss: 0.3923 - accuracy: 0.8761\n",
      "Epoch 228/1000\n",
      "1200/1200 [==============================] - 1s 838us/step - loss: 0.3943 - accuracy: 0.8780\n",
      "Epoch 229/1000\n",
      "1200/1200 [==============================] - 1s 844us/step - loss: 0.3930 - accuracy: 0.8774\n",
      "Epoch 230/1000\n",
      "1200/1200 [==============================] - 1s 874us/step - loss: 0.3935 - accuracy: 0.8763\n",
      "Epoch 231/1000\n",
      "1200/1200 [==============================] - 1s 866us/step - loss: 0.3948 - accuracy: 0.8771\n",
      "Epoch 232/1000\n",
      "1200/1200 [==============================] - 1s 854us/step - loss: 0.3947 - accuracy: 0.8780\n",
      "Epoch 233/1000\n",
      "1200/1200 [==============================] - 1s 873us/step - loss: 0.3928 - accuracy: 0.8792\n",
      "Epoch 234/1000\n",
      "1200/1200 [==============================] - 1s 850us/step - loss: 0.3928 - accuracy: 0.8767\n",
      "Epoch 235/1000\n",
      "1200/1200 [==============================] - 1s 858us/step - loss: 0.3939 - accuracy: 0.8765\n",
      "Epoch 236/1000\n",
      "1200/1200 [==============================] - 1s 812us/step - loss: 0.3939 - accuracy: 0.8769\n",
      "Epoch 237/1000\n",
      "1200/1200 [==============================] - 1s 818us/step - loss: 0.3927 - accuracy: 0.8765\n",
      "Epoch 238/1000\n",
      "1200/1200 [==============================] - 1s 809us/step - loss: 0.3952 - accuracy: 0.8758\n",
      "Epoch 239/1000\n",
      "1200/1200 [==============================] - 1s 815us/step - loss: 0.3947 - accuracy: 0.8779\n",
      "Epoch 240/1000\n",
      "1200/1200 [==============================] - 1s 840us/step - loss: 0.3938 - accuracy: 0.8765\n",
      "Epoch 241/1000\n",
      "1200/1200 [==============================] - 1s 807us/step - loss: 0.3948 - accuracy: 0.8778\n",
      "Epoch 242/1000\n",
      "1200/1200 [==============================] - 1s 815us/step - loss: 0.3947 - accuracy: 0.8772\n",
      "Epoch 243/1000\n",
      "1200/1200 [==============================] - 1s 812us/step - loss: 0.3934 - accuracy: 0.8766\n",
      "Epoch 244/1000\n",
      "1200/1200 [==============================] - 1s 816us/step - loss: 0.3940 - accuracy: 0.8774\n",
      "Epoch 245/1000\n",
      "1200/1200 [==============================] - 1s 814us/step - loss: 0.3929 - accuracy: 0.8766\n",
      "Epoch 246/1000\n",
      "1200/1200 [==============================] - 1s 817us/step - loss: 0.3960 - accuracy: 0.8768\n",
      "Epoch 247/1000\n",
      "1200/1200 [==============================] - 1s 802us/step - loss: 0.3935 - accuracy: 0.8760\n",
      "Epoch 248/1000\n",
      "1200/1200 [==============================] - 1s 814us/step - loss: 0.3937 - accuracy: 0.8772\n",
      "Epoch 249/1000\n",
      "1200/1200 [==============================] - 1s 822us/step - loss: 0.3938 - accuracy: 0.8780\n",
      "Epoch 250/1000\n",
      "1200/1200 [==============================] - 1s 807us/step - loss: 0.3942 - accuracy: 0.8785\n",
      "Epoch 251/1000\n",
      "1200/1200 [==============================] - 1s 814us/step - loss: 0.3948 - accuracy: 0.8771\n",
      "Epoch 252/1000\n",
      "1200/1200 [==============================] - 1s 800us/step - loss: 0.3947 - accuracy: 0.8772\n",
      "Epoch 253/1000\n",
      "1200/1200 [==============================] - 1s 820us/step - loss: 0.3938 - accuracy: 0.8768\n",
      "Epoch 254/1000\n",
      "1200/1200 [==============================] - 1s 835us/step - loss: 0.3947 - accuracy: 0.8771\n",
      "Epoch 255/1000\n",
      "1200/1200 [==============================] - 1s 822us/step - loss: 0.3958 - accuracy: 0.8773\n",
      "Epoch 256/1000\n",
      "1200/1200 [==============================] - 1s 820us/step - loss: 0.3936 - accuracy: 0.8772\n",
      "Epoch 257/1000\n",
      "1200/1200 [==============================] - 1s 817us/step - loss: 0.3947 - accuracy: 0.8768\n",
      "Epoch 258/1000\n",
      "1200/1200 [==============================] - 1s 813us/step - loss: 0.3943 - accuracy: 0.8776\n",
      "Epoch 259/1000\n",
      "1200/1200 [==============================] - 1s 846us/step - loss: 0.3959 - accuracy: 0.8759\n",
      "Epoch 260/1000\n",
      "1200/1200 [==============================] - 1s 822us/step - loss: 0.3943 - accuracy: 0.8764\n",
      "Epoch 261/1000\n",
      "1200/1200 [==============================] - 1s 817us/step - loss: 0.3948 - accuracy: 0.8776\n",
      "Epoch 262/1000\n",
      "1200/1200 [==============================] - 1s 835us/step - loss: 0.3945 - accuracy: 0.8774\n",
      "Epoch 263/1000\n",
      "1200/1200 [==============================] - 1s 872us/step - loss: 0.3948 - accuracy: 0.8775\n",
      "Epoch 264/1000\n",
      "1200/1200 [==============================] - 1s 867us/step - loss: 0.3942 - accuracy: 0.8785\n",
      "Epoch 265/1000\n",
      "1200/1200 [==============================] - 1s 846us/step - loss: 0.3947 - accuracy: 0.8789\n",
      "Epoch 266/1000\n",
      "1200/1200 [==============================] - 1s 810us/step - loss: 0.3953 - accuracy: 0.8765\n",
      "Epoch 267/1000\n",
      "1200/1200 [==============================] - 1s 817us/step - loss: 0.3957 - accuracy: 0.8768\n",
      "Epoch 268/1000\n",
      "1200/1200 [==============================] - 1s 829us/step - loss: 0.3940 - accuracy: 0.8779\n",
      "Epoch 269/1000\n",
      "1200/1200 [==============================] - 1s 801us/step - loss: 0.3936 - accuracy: 0.8772\n",
      "Epoch 270/1000\n",
      "1200/1200 [==============================] - 1s 807us/step - loss: 0.3940 - accuracy: 0.8762\n",
      "Epoch 271/1000\n",
      "1200/1200 [==============================] - 1s 821us/step - loss: 0.3952 - accuracy: 0.8766\n",
      "Epoch 272/1000\n",
      "1200/1200 [==============================] - 1s 835us/step - loss: 0.3941 - accuracy: 0.8781\n",
      "Epoch 273/1000\n",
      "1200/1200 [==============================] - 1s 817us/step - loss: 0.3939 - accuracy: 0.8767\n",
      "Epoch 274/1000\n",
      "1200/1200 [==============================] - 1s 823us/step - loss: 0.3959 - accuracy: 0.8783\n",
      "Epoch 275/1000\n",
      "1200/1200 [==============================] - 1s 830us/step - loss: 0.3950 - accuracy: 0.8783\n",
      "Epoch 276/1000\n",
      "1200/1200 [==============================] - 1s 838us/step - loss: 0.3950 - accuracy: 0.8774\n",
      "Epoch 277/1000\n",
      "1200/1200 [==============================] - 1s 856us/step - loss: 0.3941 - accuracy: 0.8773\n",
      "Epoch 278/1000\n",
      "1200/1200 [==============================] - 1s 796us/step - loss: 0.3954 - accuracy: 0.8779\n",
      "Epoch 279/1000\n",
      "1200/1200 [==============================] - 1s 809us/step - loss: 0.3940 - accuracy: 0.8782\n",
      "Epoch 280/1000\n",
      "1200/1200 [==============================] - 1s 866us/step - loss: 0.3943 - accuracy: 0.8776\n",
      "Epoch 281/1000\n",
      "1200/1200 [==============================] - 1s 858us/step - loss: 0.3932 - accuracy: 0.8775\n",
      "Epoch 282/1000\n",
      "1200/1200 [==============================] - 1s 817us/step - loss: 0.3946 - accuracy: 0.8765\n",
      "Epoch 283/1000\n",
      "1200/1200 [==============================] - 1s 832us/step - loss: 0.3938 - accuracy: 0.8768\n",
      "Epoch 284/1000\n",
      "1200/1200 [==============================] - 1s 842us/step - loss: 0.3938 - accuracy: 0.8767\n",
      "Epoch 285/1000\n",
      "1200/1200 [==============================] - 1s 828us/step - loss: 0.3942 - accuracy: 0.8768\n",
      "Epoch 286/1000\n",
      "1200/1200 [==============================] - 1s 857us/step - loss: 0.3946 - accuracy: 0.8779\n",
      "Epoch 287/1000\n",
      "1200/1200 [==============================] - 1s 823us/step - loss: 0.3931 - accuracy: 0.8770\n",
      "Epoch 288/1000\n",
      "1200/1200 [==============================] - 1s 839us/step - loss: 0.3930 - accuracy: 0.8781\n",
      "Epoch 289/1000\n",
      "1200/1200 [==============================] - 1s 834us/step - loss: 0.3943 - accuracy: 0.8768\n",
      "Epoch 290/1000\n",
      "1200/1200 [==============================] - 1s 879us/step - loss: 0.3941 - accuracy: 0.8778\n",
      "Epoch 291/1000\n",
      "1200/1200 [==============================] - 1s 823us/step - loss: 0.3945 - accuracy: 0.8777\n",
      "Epoch 292/1000\n",
      "1200/1200 [==============================] - 1s 826us/step - loss: 0.3952 - accuracy: 0.8778\n",
      "Epoch 293/1000\n",
      "1200/1200 [==============================] - 1s 826us/step - loss: 0.3969 - accuracy: 0.8766\n",
      "Epoch 294/1000\n",
      "1200/1200 [==============================] - 1s 831us/step - loss: 0.3949 - accuracy: 0.8762\n",
      "Epoch 295/1000\n",
      "1200/1200 [==============================] - 1s 824us/step - loss: 0.3942 - accuracy: 0.8772\n",
      "Epoch 296/1000\n",
      "1200/1200 [==============================] - 1s 813us/step - loss: 0.3946 - accuracy: 0.8769\n",
      "Epoch 297/1000\n",
      "1200/1200 [==============================] - 1s 826us/step - loss: 0.3951 - accuracy: 0.8761\n",
      "Epoch 298/1000\n",
      "1200/1200 [==============================] - 1s 811us/step - loss: 0.3947 - accuracy: 0.8778\n",
      "Epoch 299/1000\n",
      "1200/1200 [==============================] - 1s 842us/step - loss: 0.3948 - accuracy: 0.8772\n",
      "Epoch 300/1000\n",
      "1200/1200 [==============================] - 1s 847us/step - loss: 0.3944 - accuracy: 0.8772\n",
      "Epoch 301/1000\n",
      "1200/1200 [==============================] - 1s 854us/step - loss: 0.3957 - accuracy: 0.8769\n",
      "Epoch 302/1000\n",
      "1200/1200 [==============================] - 1s 857us/step - loss: 0.3936 - accuracy: 0.8783\n",
      "Epoch 303/1000\n",
      "1200/1200 [==============================] - 1s 850us/step - loss: 0.3973 - accuracy: 0.8754\n",
      "Epoch 304/1000\n",
      "1200/1200 [==============================] - 1s 820us/step - loss: 0.3940 - accuracy: 0.8773\n",
      "Epoch 305/1000\n",
      "1200/1200 [==============================] - 1s 863us/step - loss: 0.3949 - accuracy: 0.8769\n",
      "Epoch 306/1000\n",
      "1200/1200 [==============================] - 1s 848us/step - loss: 0.3945 - accuracy: 0.8784\n",
      "Epoch 307/1000\n",
      "1200/1200 [==============================] - 1s 855us/step - loss: 0.3945 - accuracy: 0.8777\n",
      "Epoch 308/1000\n",
      "1200/1200 [==============================] - 1s 841us/step - loss: 0.3946 - accuracy: 0.8775\n",
      "Epoch 309/1000\n",
      "1200/1200 [==============================] - 1s 840us/step - loss: 0.3958 - accuracy: 0.8782\n",
      "Epoch 310/1000\n",
      "1200/1200 [==============================] - 1s 850us/step - loss: 0.3940 - accuracy: 0.8782\n",
      "Epoch 311/1000\n",
      "1200/1200 [==============================] - 1s 872us/step - loss: 0.3938 - accuracy: 0.8775\n",
      "Epoch 312/1000\n",
      "1200/1200 [==============================] - 1s 860us/step - loss: 0.3941 - accuracy: 0.8776\n",
      "Epoch 313/1000\n",
      "1200/1200 [==============================] - 1s 858us/step - loss: 0.3931 - accuracy: 0.8777\n",
      "Epoch 314/1000\n",
      "1200/1200 [==============================] - 1s 873us/step - loss: 0.3933 - accuracy: 0.8773\n",
      "Epoch 315/1000\n",
      "1200/1200 [==============================] - 1s 879us/step - loss: 0.3928 - accuracy: 0.8771\n",
      "Epoch 316/1000\n",
      "1200/1200 [==============================] - 1s 871us/step - loss: 0.3931 - accuracy: 0.8778\n",
      "Epoch 317/1000\n",
      "1200/1200 [==============================] - 1s 857us/step - loss: 0.3927 - accuracy: 0.8786\n",
      "Epoch 318/1000\n",
      "1200/1200 [==============================] - 1s 859us/step - loss: 0.3932 - accuracy: 0.8774\n",
      "Epoch 319/1000\n",
      "1200/1200 [==============================] - 1s 866us/step - loss: 0.3932 - accuracy: 0.8785\n",
      "Epoch 320/1000\n",
      "1200/1200 [==============================] - 1s 837us/step - loss: 0.3936 - accuracy: 0.8769\n",
      "Epoch 321/1000\n",
      "1200/1200 [==============================] - 1s 850us/step - loss: 0.3927 - accuracy: 0.8771\n",
      "Epoch 322/1000\n",
      "1200/1200 [==============================] - 1s 839us/step - loss: 0.3930 - accuracy: 0.8768\n",
      "Epoch 323/1000\n",
      "1200/1200 [==============================] - 1s 936us/step - loss: 0.3926 - accuracy: 0.8776\n",
      "Epoch 324/1000\n",
      "1200/1200 [==============================] - 1s 1ms/step - loss: 0.3930 - accuracy: 0.8761\n",
      "Epoch 325/1000\n",
      "1200/1200 [==============================] - 1s 846us/step - loss: 0.3934 - accuracy: 0.8775\n",
      "Epoch 326/1000\n",
      "1200/1200 [==============================] - 1s 847us/step - loss: 0.3936 - accuracy: 0.8778\n",
      "Epoch 327/1000\n",
      "1200/1200 [==============================] - 1s 865us/step - loss: 0.3932 - accuracy: 0.8791\n",
      "Epoch 328/1000\n",
      "1200/1200 [==============================] - 1s 817us/step - loss: 0.3932 - accuracy: 0.8787\n",
      "Epoch 329/1000\n",
      "1200/1200 [==============================] - 1s 825us/step - loss: 0.3931 - accuracy: 0.8772\n",
      "Epoch 330/1000\n",
      "1200/1200 [==============================] - 1s 815us/step - loss: 0.3942 - accuracy: 0.8781\n",
      "Epoch 331/1000\n",
      "1200/1200 [==============================] - 1s 841us/step - loss: 0.3929 - accuracy: 0.8780\n",
      "Epoch 332/1000\n",
      "1200/1200 [==============================] - 1s 799us/step - loss: 0.3935 - accuracy: 0.8782\n",
      "Epoch 333/1000\n",
      "1200/1200 [==============================] - 1s 824us/step - loss: 0.3950 - accuracy: 0.8777\n",
      "Epoch 334/1000\n",
      "1200/1200 [==============================] - 1s 815us/step - loss: 0.3948 - accuracy: 0.8786\n",
      "Epoch 335/1000\n",
      "1200/1200 [==============================] - 1s 833us/step - loss: 0.3935 - accuracy: 0.8766\n",
      "Epoch 336/1000\n",
      "1200/1200 [==============================] - 1s 813us/step - loss: 0.3942 - accuracy: 0.8773\n",
      "Epoch 337/1000\n",
      "1200/1200 [==============================] - 1s 813us/step - loss: 0.3921 - accuracy: 0.8783\n",
      "Epoch 338/1000\n",
      "1200/1200 [==============================] - 1s 818us/step - loss: 0.3944 - accuracy: 0.8791\n",
      "Epoch 339/1000\n",
      "1200/1200 [==============================] - 1s 835us/step - loss: 0.3944 - accuracy: 0.8779\n",
      "Epoch 340/1000\n",
      "1200/1200 [==============================] - 1s 816us/step - loss: 0.3926 - accuracy: 0.8780\n",
      "Epoch 341/1000\n",
      "1200/1200 [==============================] - 1s 809us/step - loss: 0.3937 - accuracy: 0.8773\n",
      "Epoch 342/1000\n",
      "1200/1200 [==============================] - 1s 816us/step - loss: 0.3920 - accuracy: 0.8784\n",
      "Epoch 343/1000\n",
      "1200/1200 [==============================] - 1s 826us/step - loss: 0.3926 - accuracy: 0.8778\n",
      "Epoch 344/1000\n",
      "1200/1200 [==============================] - 1s 817us/step - loss: 0.3936 - accuracy: 0.8788\n",
      "Epoch 345/1000\n",
      "1200/1200 [==============================] - 1s 811us/step - loss: 0.3923 - accuracy: 0.8784\n",
      "Epoch 346/1000\n",
      "1200/1200 [==============================] - 1s 812us/step - loss: 0.3954 - accuracy: 0.8780\n",
      "Epoch 347/1000\n",
      "1200/1200 [==============================] - 1s 830us/step - loss: 0.3931 - accuracy: 0.8778\n",
      "Epoch 348/1000\n",
      "1200/1200 [==============================] - 1s 813us/step - loss: 0.3938 - accuracy: 0.8766\n",
      "Epoch 349/1000\n",
      "1200/1200 [==============================] - 1s 817us/step - loss: 0.3951 - accuracy: 0.8776\n",
      "Epoch 350/1000\n",
      "1200/1200 [==============================] - 1s 815us/step - loss: 0.3930 - accuracy: 0.8782\n",
      "Epoch 351/1000\n",
      "1200/1200 [==============================] - 1s 851us/step - loss: 0.3934 - accuracy: 0.8781\n",
      "Epoch 352/1000\n",
      "1200/1200 [==============================] - 1s 819us/step - loss: 0.3934 - accuracy: 0.8783\n",
      "Epoch 353/1000\n",
      "1200/1200 [==============================] - 1s 829us/step - loss: 0.3941 - accuracy: 0.8778\n",
      "Epoch 354/1000\n",
      "1200/1200 [==============================] - 1s 813us/step - loss: 0.3931 - accuracy: 0.8782\n",
      "Epoch 355/1000\n",
      "1200/1200 [==============================] - 1s 849us/step - loss: 0.3939 - accuracy: 0.8784\n",
      "Epoch 356/1000\n",
      "1200/1200 [==============================] - 1s 856us/step - loss: 0.3946 - accuracy: 0.8780\n",
      "Epoch 357/1000\n",
      "1200/1200 [==============================] - 1s 845us/step - loss: 0.3952 - accuracy: 0.8776\n",
      "Epoch 358/1000\n",
      "1200/1200 [==============================] - 1s 854us/step - loss: 0.3945 - accuracy: 0.8773\n",
      "Epoch 359/1000\n",
      "1200/1200 [==============================] - 1s 838us/step - loss: 0.3936 - accuracy: 0.8773\n",
      "Epoch 360/1000\n",
      "1200/1200 [==============================] - 1s 816us/step - loss: 0.3933 - accuracy: 0.8788\n",
      "Epoch 361/1000\n",
      "1200/1200 [==============================] - 1s 816us/step - loss: 0.3939 - accuracy: 0.8781\n",
      "Epoch 362/1000\n",
      "1200/1200 [==============================] - 1s 819us/step - loss: 0.3940 - accuracy: 0.8787\n",
      "Epoch 363/1000\n",
      "1200/1200 [==============================] - 1s 839us/step - loss: 0.3930 - accuracy: 0.8783\n",
      "Epoch 364/1000\n",
      "1200/1200 [==============================] - 1s 820us/step - loss: 0.3941 - accuracy: 0.8782\n",
      "Epoch 365/1000\n",
      "1200/1200 [==============================] - 1s 818us/step - loss: 0.3925 - accuracy: 0.8778\n",
      "Epoch 366/1000\n",
      "1200/1200 [==============================] - 1s 837us/step - loss: 0.3938 - accuracy: 0.8786\n",
      "Epoch 367/1000\n",
      "1200/1200 [==============================] - 1s 814us/step - loss: 0.3949 - accuracy: 0.8798\n",
      "Epoch 368/1000\n",
      "1200/1200 [==============================] - 1s 808us/step - loss: 0.3938 - accuracy: 0.8783\n",
      "Epoch 369/1000\n",
      "1200/1200 [==============================] - 1s 821us/step - loss: 0.3931 - accuracy: 0.8786\n",
      "Epoch 370/1000\n",
      "1200/1200 [==============================] - 1s 848us/step - loss: 0.3939 - accuracy: 0.8792\n",
      "Epoch 371/1000\n",
      "1200/1200 [==============================] - 1s 817us/step - loss: 0.3948 - accuracy: 0.8779\n",
      "Epoch 372/1000\n",
      "1200/1200 [==============================] - 1s 809us/step - loss: 0.3940 - accuracy: 0.8785\n",
      "Epoch 373/1000\n",
      "1200/1200 [==============================] - 1s 819us/step - loss: 0.3933 - accuracy: 0.8785\n",
      "Epoch 374/1000\n",
      "1200/1200 [==============================] - 1s 834us/step - loss: 0.3949 - accuracy: 0.8782\n",
      "Epoch 375/1000\n",
      "1200/1200 [==============================] - 1s 817us/step - loss: 0.3950 - accuracy: 0.8771\n",
      "Epoch 376/1000\n",
      "1200/1200 [==============================] - 1s 811us/step - loss: 0.3930 - accuracy: 0.8784\n",
      "Epoch 377/1000\n",
      "1200/1200 [==============================] - 1s 813us/step - loss: 0.3937 - accuracy: 0.8774\n",
      "Epoch 378/1000\n",
      "1200/1200 [==============================] - 1s 845us/step - loss: 0.3955 - accuracy: 0.8776\n",
      "Epoch 379/1000\n",
      "1200/1200 [==============================] - 1s 806us/step - loss: 0.3950 - accuracy: 0.8770\n",
      "Epoch 380/1000\n",
      "1200/1200 [==============================] - 1s 826us/step - loss: 0.3945 - accuracy: 0.8787\n",
      "Epoch 381/1000\n",
      "1200/1200 [==============================] - 1s 807us/step - loss: 0.3944 - accuracy: 0.8788\n",
      "Epoch 382/1000\n",
      "1200/1200 [==============================] - 1s 855us/step - loss: 0.3954 - accuracy: 0.8781\n",
      "Epoch 383/1000\n",
      "1200/1200 [==============================] - 1s 815us/step - loss: 0.3937 - accuracy: 0.8790\n",
      "Epoch 384/1000\n",
      "1200/1200 [==============================] - 1s 821us/step - loss: 0.3949 - accuracy: 0.8770\n",
      "Epoch 385/1000\n",
      "1200/1200 [==============================] - 1s 829us/step - loss: 0.3960 - accuracy: 0.8768\n",
      "Epoch 386/1000\n",
      "1200/1200 [==============================] - 1s 831us/step - loss: 0.3940 - accuracy: 0.8785\n",
      "Epoch 387/1000\n",
      "1200/1200 [==============================] - 1s 844us/step - loss: 0.3960 - accuracy: 0.8786\n",
      "Epoch 388/1000\n",
      "1200/1200 [==============================] - 1s 839us/step - loss: 0.3957 - accuracy: 0.8785\n",
      "Epoch 389/1000\n",
      "1200/1200 [==============================] - 1s 877us/step - loss: 0.3946 - accuracy: 0.8778\n",
      "Epoch 390/1000\n",
      "1200/1200 [==============================] - 1s 818us/step - loss: 0.3965 - accuracy: 0.8763\n",
      "Epoch 391/1000\n",
      "1200/1200 [==============================] - 1s 826us/step - loss: 0.3957 - accuracy: 0.8780\n",
      "Epoch 392/1000\n",
      "1200/1200 [==============================] - 1s 809us/step - loss: 0.3954 - accuracy: 0.8780\n",
      "Epoch 393/1000\n",
      "1200/1200 [==============================] - 1s 834us/step - loss: 0.3938 - accuracy: 0.8772\n",
      "Epoch 394/1000\n",
      "1200/1200 [==============================] - 1s 813us/step - loss: 0.3944 - accuracy: 0.8779\n",
      "Epoch 395/1000\n",
      "1200/1200 [==============================] - 1s 823us/step - loss: 0.3928 - accuracy: 0.8784\n",
      "Epoch 396/1000\n",
      "1200/1200 [==============================] - 1s 835us/step - loss: 0.3951 - accuracy: 0.8790\n",
      "Epoch 397/1000\n",
      "1200/1200 [==============================] - 1s 829us/step - loss: 0.3948 - accuracy: 0.8788\n",
      "Epoch 398/1000\n",
      "1200/1200 [==============================] - 1s 831us/step - loss: 0.3962 - accuracy: 0.8777\n",
      "Epoch 399/1000\n",
      "1200/1200 [==============================] - 1s 847us/step - loss: 0.3948 - accuracy: 0.8775\n",
      "Epoch 400/1000\n",
      "1200/1200 [==============================] - 1s 874us/step - loss: 0.3965 - accuracy: 0.8782\n",
      "Epoch 401/1000\n",
      "1200/1200 [==============================] - 1s 821us/step - loss: 0.3965 - accuracy: 0.8788\n",
      "Epoch 402/1000\n",
      "1200/1200 [==============================] - 1s 823us/step - loss: 0.3954 - accuracy: 0.8782\n",
      "Epoch 403/1000\n",
      "1200/1200 [==============================] - 1s 818us/step - loss: 0.3952 - accuracy: 0.8784\n",
      "Epoch 404/1000\n",
      "1200/1200 [==============================] - 1s 846us/step - loss: 0.3949 - accuracy: 0.8768\n",
      "Epoch 405/1000\n",
      "1200/1200 [==============================] - 1s 816us/step - loss: 0.3956 - accuracy: 0.8765\n",
      "Epoch 406/1000\n",
      "1200/1200 [==============================] - 1s 826us/step - loss: 0.3948 - accuracy: 0.8783\n",
      "Epoch 407/1000\n",
      "1200/1200 [==============================] - 1s 855us/step - loss: 0.3969 - accuracy: 0.8769\n",
      "Epoch 408/1000\n",
      "1200/1200 [==============================] - 1s 866us/step - loss: 0.3945 - accuracy: 0.8785\n",
      "Epoch 409/1000\n",
      "1200/1200 [==============================] - 1s 840us/step - loss: 0.3957 - accuracy: 0.8790\n",
      "Epoch 410/1000\n",
      "1200/1200 [==============================] - 1s 858us/step - loss: 0.3943 - accuracy: 0.8779\n",
      "Epoch 411/1000\n",
      "1200/1200 [==============================] - 1s 876us/step - loss: 0.3952 - accuracy: 0.8777\n",
      "Epoch 412/1000\n",
      "1200/1200 [==============================] - 1s 850us/step - loss: 0.3960 - accuracy: 0.8768\n",
      "Epoch 413/1000\n",
      "1200/1200 [==============================] - 1s 870us/step - loss: 0.3944 - accuracy: 0.8760\n",
      "Epoch 414/1000\n",
      "1200/1200 [==============================] - 1s 852us/step - loss: 0.3963 - accuracy: 0.8783\n",
      "Epoch 415/1000\n",
      "1200/1200 [==============================] - 1s 831us/step - loss: 0.3958 - accuracy: 0.8790\n",
      "Epoch 416/1000\n",
      "1200/1200 [==============================] - 1s 833us/step - loss: 0.3972 - accuracy: 0.8771\n",
      "Epoch 417/1000\n",
      "1200/1200 [==============================] - 1s 842us/step - loss: 0.3954 - accuracy: 0.8780\n",
      "Epoch 418/1000\n",
      "1200/1200 [==============================] - 1s 835us/step - loss: 0.3965 - accuracy: 0.8771\n",
      "Epoch 419/1000\n",
      "1200/1200 [==============================] - 1s 825us/step - loss: 0.3957 - accuracy: 0.8770\n",
      "Epoch 420/1000\n",
      "1200/1200 [==============================] - 1s 830us/step - loss: 0.3959 - accuracy: 0.8771\n",
      "Epoch 421/1000\n",
      "1200/1200 [==============================] - 1s 847us/step - loss: 0.3958 - accuracy: 0.8776\n",
      "Epoch 422/1000\n",
      "1200/1200 [==============================] - 1s 821us/step - loss: 0.3954 - accuracy: 0.8795\n",
      "Epoch 423/1000\n",
      "1200/1200 [==============================] - 1s 852us/step - loss: 0.3955 - accuracy: 0.8793\n",
      "Epoch 424/1000\n",
      "1200/1200 [==============================] - 1s 914us/step - loss: 0.3978 - accuracy: 0.8779\n",
      "Epoch 425/1000\n",
      "1200/1200 [==============================] - 1s 877us/step - loss: 0.3947 - accuracy: 0.8779\n",
      "Epoch 426/1000\n",
      "1200/1200 [==============================] - 1s 861us/step - loss: 0.3961 - accuracy: 0.8768\n",
      "Epoch 427/1000\n",
      "1200/1200 [==============================] - 1s 831us/step - loss: 0.3956 - accuracy: 0.8791\n",
      "Epoch 428/1000\n",
      "1200/1200 [==============================] - 1s 893us/step - loss: 0.3981 - accuracy: 0.8769\n",
      "Epoch 429/1000\n",
      "1200/1200 [==============================] - 1s 861us/step - loss: 0.3952 - accuracy: 0.8779\n",
      "Epoch 430/1000\n",
      "1200/1200 [==============================] - 1s 824us/step - loss: 0.3956 - accuracy: 0.8783\n",
      "Epoch 431/1000\n",
      "1200/1200 [==============================] - 1s 834us/step - loss: 0.3964 - accuracy: 0.8773\n",
      "Epoch 432/1000\n",
      "1200/1200 [==============================] - 1s 827us/step - loss: 0.3973 - accuracy: 0.8772\n",
      "Epoch 433/1000\n",
      "1200/1200 [==============================] - 1s 811us/step - loss: 0.3945 - accuracy: 0.8788\n",
      "Epoch 434/1000\n",
      "1200/1200 [==============================] - 1s 825us/step - loss: 0.3960 - accuracy: 0.8788\n",
      "Epoch 435/1000\n",
      "1200/1200 [==============================] - 1s 846us/step - loss: 0.3968 - accuracy: 0.8775\n",
      "Epoch 436/1000\n",
      "1200/1200 [==============================] - 1s 854us/step - loss: 0.3973 - accuracy: 0.8771\n",
      "Epoch 437/1000\n",
      "1200/1200 [==============================] - 1s 847us/step - loss: 0.3961 - accuracy: 0.8782\n",
      "Epoch 438/1000\n",
      "1200/1200 [==============================] - 1s 866us/step - loss: 0.3961 - accuracy: 0.8766\n",
      "Epoch 439/1000\n",
      "1200/1200 [==============================] - 1s 857us/step - loss: 0.3944 - accuracy: 0.8790\n",
      "Epoch 440/1000\n",
      "1200/1200 [==============================] - 1s 839us/step - loss: 0.3963 - accuracy: 0.8780\n",
      "Epoch 441/1000\n",
      "1200/1200 [==============================] - 1s 876us/step - loss: 0.3963 - accuracy: 0.8774\n",
      "Epoch 442/1000\n",
      "1200/1200 [==============================] - 1s 833us/step - loss: 0.3952 - accuracy: 0.8781\n",
      "Epoch 443/1000\n",
      "1200/1200 [==============================] - 1s 862us/step - loss: 0.3964 - accuracy: 0.8773\n",
      "Epoch 444/1000\n",
      "1200/1200 [==============================] - 1s 840us/step - loss: 0.3974 - accuracy: 0.8779\n",
      "Epoch 445/1000\n",
      "1200/1200 [==============================] - 1s 883us/step - loss: 0.3975 - accuracy: 0.8781\n",
      "Epoch 446/1000\n",
      "1200/1200 [==============================] - 1s 836us/step - loss: 0.3969 - accuracy: 0.8785\n",
      "Epoch 447/1000\n",
      "1200/1200 [==============================] - 1s 836us/step - loss: 0.3958 - accuracy: 0.8789\n",
      "Epoch 448/1000\n",
      "1200/1200 [==============================] - 1s 858us/step - loss: 0.3976 - accuracy: 0.8779\n",
      "Epoch 449/1000\n",
      "1200/1200 [==============================] - 1s 873us/step - loss: 0.3952 - accuracy: 0.8772\n",
      "Epoch 450/1000\n",
      "1200/1200 [==============================] - 1s 850us/step - loss: 0.3967 - accuracy: 0.8777\n",
      "Epoch 451/1000\n",
      "1200/1200 [==============================] - 1s 896us/step - loss: 0.3964 - accuracy: 0.8776\n",
      "Epoch 452/1000\n",
      "1200/1200 [==============================] - 1s 823us/step - loss: 0.3968 - accuracy: 0.8792\n",
      "Epoch 453/1000\n",
      "1200/1200 [==============================] - 1s 827us/step - loss: 0.3978 - accuracy: 0.8788\n",
      "Epoch 454/1000\n",
      "1200/1200 [==============================] - 1s 818us/step - loss: 0.3980 - accuracy: 0.8773\n",
      "Epoch 455/1000\n",
      "1200/1200 [==============================] - 1s 837us/step - loss: 0.3967 - accuracy: 0.8790\n",
      "Epoch 456/1000\n",
      "1200/1200 [==============================] - 1s 814us/step - loss: 0.3965 - accuracy: 0.8783\n",
      "Epoch 457/1000\n",
      "1200/1200 [==============================] - 1s 818us/step - loss: 0.3968 - accuracy: 0.8779\n",
      "Epoch 458/1000\n",
      "1200/1200 [==============================] - 1s 846us/step - loss: 0.3976 - accuracy: 0.8789\n",
      "Epoch 459/1000\n",
      "1200/1200 [==============================] - 1s 813us/step - loss: 0.3979 - accuracy: 0.8781\n",
      "Epoch 460/1000\n",
      "1200/1200 [==============================] - 1s 822us/step - loss: 0.3968 - accuracy: 0.8799\n",
      "Epoch 461/1000\n",
      "1200/1200 [==============================] - 1s 833us/step - loss: 0.3963 - accuracy: 0.8796\n",
      "Epoch 462/1000\n",
      "1200/1200 [==============================] - 1s 829us/step - loss: 0.3970 - accuracy: 0.8780\n",
      "Epoch 463/1000\n",
      "1200/1200 [==============================] - 1s 819us/step - loss: 0.3984 - accuracy: 0.8787\n",
      "Epoch 464/1000\n",
      "1200/1200 [==============================] - 1s 839us/step - loss: 0.3979 - accuracy: 0.8780\n",
      "Epoch 465/1000\n",
      "1200/1200 [==============================] - 1s 823us/step - loss: 0.3982 - accuracy: 0.8772\n",
      "Epoch 466/1000\n",
      "1200/1200 [==============================] - 1s 817us/step - loss: 0.3975 - accuracy: 0.8783\n",
      "Epoch 467/1000\n",
      "1200/1200 [==============================] - 1s 821us/step - loss: 0.3970 - accuracy: 0.8786\n",
      "Epoch 468/1000\n",
      "1200/1200 [==============================] - 1s 834us/step - loss: 0.3983 - accuracy: 0.8796\n",
      "Epoch 469/1000\n",
      "1200/1200 [==============================] - 1s 829us/step - loss: 0.3972 - accuracy: 0.8788\n",
      "Epoch 470/1000\n",
      "1200/1200 [==============================] - 1s 814us/step - loss: 0.3980 - accuracy: 0.8767\n",
      "Epoch 471/1000\n",
      "1200/1200 [==============================] - 1s 872us/step - loss: 0.3980 - accuracy: 0.8790\n",
      "Epoch 472/1000\n",
      "1200/1200 [==============================] - 1s 823us/step - loss: 0.3974 - accuracy: 0.8773\n",
      "Epoch 473/1000\n",
      "1200/1200 [==============================] - 1s 847us/step - loss: 0.3967 - accuracy: 0.8786\n",
      "Epoch 474/1000\n",
      "1200/1200 [==============================] - 1s 862us/step - loss: 0.3989 - accuracy: 0.8777\n",
      "Epoch 475/1000\n",
      "1200/1200 [==============================] - 1s 849us/step - loss: 0.3984 - accuracy: 0.8792\n",
      "Epoch 476/1000\n",
      "1200/1200 [==============================] - 1s 839us/step - loss: 0.3979 - accuracy: 0.8777\n",
      "Epoch 477/1000\n",
      "1200/1200 [==============================] - 1s 893us/step - loss: 0.3972 - accuracy: 0.8788\n",
      "Epoch 478/1000\n",
      "1200/1200 [==============================] - 1s 842us/step - loss: 0.3970 - accuracy: 0.8793\n",
      "Epoch 479/1000\n",
      "1200/1200 [==============================] - 1s 845us/step - loss: 0.3960 - accuracy: 0.8773\n",
      "Epoch 480/1000\n",
      "1200/1200 [==============================] - 1s 895us/step - loss: 0.3971 - accuracy: 0.8808\n",
      "Epoch 481/1000\n",
      "1200/1200 [==============================] - 1s 865us/step - loss: 0.3974 - accuracy: 0.8780\n",
      "Epoch 482/1000\n",
      "1200/1200 [==============================] - 1s 867us/step - loss: 0.3977 - accuracy: 0.8784\n",
      "Epoch 483/1000\n",
      "1200/1200 [==============================] - 1s 840us/step - loss: 0.3970 - accuracy: 0.8786\n",
      "Epoch 484/1000\n",
      "1200/1200 [==============================] - 1s 841us/step - loss: 0.3985 - accuracy: 0.8783\n",
      "Epoch 485/1000\n",
      "1200/1200 [==============================] - 1s 827us/step - loss: 0.3974 - accuracy: 0.8787\n",
      "Epoch 486/1000\n",
      "1200/1200 [==============================] - 1s 834us/step - loss: 0.3953 - accuracy: 0.8791\n",
      "Epoch 487/1000\n",
      "1200/1200 [==============================] - 1s 834us/step - loss: 0.3974 - accuracy: 0.8776\n",
      "Epoch 488/1000\n",
      "1200/1200 [==============================] - 1s 827us/step - loss: 0.3972 - accuracy: 0.8780\n",
      "Epoch 489/1000\n",
      "1200/1200 [==============================] - 1s 817us/step - loss: 0.3980 - accuracy: 0.8778\n",
      "Epoch 490/1000\n",
      "1200/1200 [==============================] - 1s 866us/step - loss: 0.3966 - accuracy: 0.8786\n",
      "Epoch 491/1000\n",
      "1200/1200 [==============================] - 1s 816us/step - loss: 0.3979 - accuracy: 0.8780\n",
      "Epoch 492/1000\n",
      "1200/1200 [==============================] - 1s 823us/step - loss: 0.3983 - accuracy: 0.8781\n",
      "Epoch 493/1000\n",
      "1200/1200 [==============================] - 1s 846us/step - loss: 0.3985 - accuracy: 0.8779\n",
      "Epoch 494/1000\n",
      "1200/1200 [==============================] - 1s 826us/step - loss: 0.3986 - accuracy: 0.8773\n",
      "Epoch 495/1000\n",
      "1200/1200 [==============================] - 1s 828us/step - loss: 0.3977 - accuracy: 0.8787\n",
      "Epoch 496/1000\n",
      "1200/1200 [==============================] - 1s 830us/step - loss: 0.3996 - accuracy: 0.8783\n",
      "Epoch 497/1000\n",
      "1200/1200 [==============================] - 1s 819us/step - loss: 0.3975 - accuracy: 0.8791\n",
      "Epoch 498/1000\n",
      "1200/1200 [==============================] - 1s 813us/step - loss: 0.3976 - accuracy: 0.8803\n",
      "Epoch 499/1000\n",
      "1200/1200 [==============================] - 1s 852us/step - loss: 0.3980 - accuracy: 0.8782\n",
      "Epoch 500/1000\n",
      "1200/1200 [==============================] - 1s 827us/step - loss: 0.4002 - accuracy: 0.8795\n",
      "Epoch 501/1000\n",
      "1200/1200 [==============================] - 1s 827us/step - loss: 0.3989 - accuracy: 0.8776\n",
      "Epoch 502/1000\n",
      "1200/1200 [==============================] - 1s 833us/step - loss: 0.3977 - accuracy: 0.8778\n",
      "Epoch 503/1000\n",
      "1200/1200 [==============================] - 1s 826us/step - loss: 0.4000 - accuracy: 0.8785\n",
      "Epoch 504/1000\n",
      "1200/1200 [==============================] - 1s 824us/step - loss: 0.3983 - accuracy: 0.8777\n",
      "Epoch 505/1000\n",
      "1200/1200 [==============================] - 1s 835us/step - loss: 0.4000 - accuracy: 0.8784\n",
      "Epoch 506/1000\n",
      "1200/1200 [==============================] - 1s 824us/step - loss: 0.3988 - accuracy: 0.8782\n",
      "Epoch 507/1000\n",
      "1200/1200 [==============================] - 1s 820us/step - loss: 0.3994 - accuracy: 0.8783\n",
      "Epoch 508/1000\n",
      "1200/1200 [==============================] - 1s 829us/step - loss: 0.3997 - accuracy: 0.8792\n",
      "Epoch 509/1000\n",
      "1200/1200 [==============================] - 1s 860us/step - loss: 0.3994 - accuracy: 0.8780\n",
      "Epoch 510/1000\n",
      "1200/1200 [==============================] - 1s 865us/step - loss: 0.3996 - accuracy: 0.8792\n",
      "Epoch 511/1000\n",
      "1200/1200 [==============================] - 1s 844us/step - loss: 0.3980 - accuracy: 0.8796\n",
      "Epoch 512/1000\n",
      "1200/1200 [==============================] - 1s 872us/step - loss: 0.3993 - accuracy: 0.8792\n",
      "Epoch 513/1000\n",
      "1200/1200 [==============================] - 1s 812us/step - loss: 0.3987 - accuracy: 0.8792\n",
      "Epoch 514/1000\n",
      "1200/1200 [==============================] - 1s 817us/step - loss: 0.4000 - accuracy: 0.8789\n",
      "Epoch 515/1000\n",
      "1200/1200 [==============================] - 1s 862us/step - loss: 0.3985 - accuracy: 0.8790\n",
      "Epoch 516/1000\n",
      "1200/1200 [==============================] - 1s 816us/step - loss: 0.3994 - accuracy: 0.8786\n",
      "Epoch 517/1000\n",
      "1200/1200 [==============================] - 1s 825us/step - loss: 0.3986 - accuracy: 0.8803\n",
      "Epoch 518/1000\n",
      "1200/1200 [==============================] - 1s 828us/step - loss: 0.3988 - accuracy: 0.8784\n",
      "Epoch 519/1000\n",
      "1200/1200 [==============================] - 1s 815us/step - loss: 0.4003 - accuracy: 0.8790\n",
      "Epoch 520/1000\n",
      "1200/1200 [==============================] - 1s 829us/step - loss: 0.3990 - accuracy: 0.8791\n",
      "Epoch 521/1000\n",
      "1200/1200 [==============================] - 1s 888us/step - loss: 0.4005 - accuracy: 0.8790\n",
      "Epoch 522/1000\n",
      "1200/1200 [==============================] - 1s 845us/step - loss: 0.3995 - accuracy: 0.8779\n",
      "Epoch 523/1000\n",
      "1200/1200 [==============================] - 1s 845us/step - loss: 0.3993 - accuracy: 0.8792\n",
      "Epoch 524/1000\n",
      "1200/1200 [==============================] - 1s 850us/step - loss: 0.4000 - accuracy: 0.8785\n",
      "Epoch 525/1000\n",
      "1200/1200 [==============================] - 1s 827us/step - loss: 0.3994 - accuracy: 0.8783\n",
      "Epoch 526/1000\n",
      "1200/1200 [==============================] - 1s 804us/step - loss: 0.4011 - accuracy: 0.8803\n",
      "Epoch 527/1000\n",
      "1200/1200 [==============================] - 1s 854us/step - loss: 0.4007 - accuracy: 0.8798\n",
      "Epoch 528/1000\n",
      "1200/1200 [==============================] - 1s 829us/step - loss: 0.3995 - accuracy: 0.8776\n",
      "Epoch 529/1000\n",
      "1200/1200 [==============================] - 1s 810us/step - loss: 0.4011 - accuracy: 0.8780\n",
      "Epoch 530/1000\n",
      "1200/1200 [==============================] - 1s 850us/step - loss: 0.4000 - accuracy: 0.8775\n",
      "Epoch 531/1000\n",
      "1200/1200 [==============================] - 1s 832us/step - loss: 0.3983 - accuracy: 0.8793\n",
      "Epoch 532/1000\n",
      "1200/1200 [==============================] - 1s 829us/step - loss: 0.4011 - accuracy: 0.8779\n",
      "Epoch 533/1000\n",
      "1200/1200 [==============================] - 1s 848us/step - loss: 0.4002 - accuracy: 0.8801\n",
      "Epoch 534/1000\n",
      "1200/1200 [==============================] - 1s 827us/step - loss: 0.4005 - accuracy: 0.8782\n",
      "Epoch 535/1000\n",
      "1200/1200 [==============================] - 1s 815us/step - loss: 0.4003 - accuracy: 0.8788\n",
      "Epoch 536/1000\n",
      "1200/1200 [==============================] - 1s 859us/step - loss: 0.4010 - accuracy: 0.8790\n",
      "Epoch 537/1000\n",
      "1200/1200 [==============================] - 1s 827us/step - loss: 0.4023 - accuracy: 0.8775\n",
      "Epoch 538/1000\n",
      "1200/1200 [==============================] - 1s 830us/step - loss: 0.4028 - accuracy: 0.8791\n",
      "Epoch 539/1000\n",
      "1200/1200 [==============================] - 1s 858us/step - loss: 0.4010 - accuracy: 0.8785\n",
      "Epoch 540/1000\n",
      "1200/1200 [==============================] - 1s 823us/step - loss: 0.4008 - accuracy: 0.8788\n",
      "Epoch 541/1000\n",
      "1200/1200 [==============================] - 1s 825us/step - loss: 0.4016 - accuracy: 0.8794\n",
      "Epoch 542/1000\n",
      "1200/1200 [==============================] - 1s 850us/step - loss: 0.4038 - accuracy: 0.8784\n",
      "Epoch 543/1000\n",
      "1200/1200 [==============================] - 1s 846us/step - loss: 0.4017 - accuracy: 0.8774\n",
      "Epoch 544/1000\n",
      "1200/1200 [==============================] - 1s 847us/step - loss: 0.4016 - accuracy: 0.8793\n",
      "Epoch 545/1000\n",
      "1200/1200 [==============================] - 1s 831us/step - loss: 0.4013 - accuracy: 0.8783\n",
      "Epoch 546/1000\n",
      "1200/1200 [==============================] - 1s 826us/step - loss: 0.4010 - accuracy: 0.8792\n",
      "Epoch 547/1000\n",
      "1200/1200 [==============================] - 1s 858us/step - loss: 0.4015 - accuracy: 0.8784\n",
      "Epoch 548/1000\n",
      "1200/1200 [==============================] - 1s 827us/step - loss: 0.4018 - accuracy: 0.8780\n",
      "Epoch 549/1000\n",
      "1200/1200 [==============================] - 1s 827us/step - loss: 0.4004 - accuracy: 0.8787\n",
      "Epoch 550/1000\n",
      "1200/1200 [==============================] - 1s 847us/step - loss: 0.4012 - accuracy: 0.8795\n",
      "Epoch 551/1000\n",
      "1200/1200 [==============================] - 1s 816us/step - loss: 0.4008 - accuracy: 0.8792\n",
      "Epoch 552/1000\n",
      "1200/1200 [==============================] - 1s 826us/step - loss: 0.3987 - accuracy: 0.8789\n",
      "Epoch 553/1000\n",
      "1200/1200 [==============================] - 1s 843us/step - loss: 0.4022 - accuracy: 0.8789\n",
      "Epoch 554/1000\n",
      "1200/1200 [==============================] - 1s 824us/step - loss: 0.4016 - accuracy: 0.8781\n",
      "Epoch 555/1000\n",
      "1200/1200 [==============================] - 1s 820us/step - loss: 0.4011 - accuracy: 0.8790\n",
      "Epoch 556/1000\n",
      "1200/1200 [==============================] - 1s 859us/step - loss: 0.4006 - accuracy: 0.8783\n",
      "Epoch 557/1000\n",
      "1200/1200 [==============================] - 1s 827us/step - loss: 0.4019 - accuracy: 0.8794\n",
      "Epoch 558/1000\n",
      "1200/1200 [==============================] - 1s 831us/step - loss: 0.4028 - accuracy: 0.8796\n",
      "Epoch 559/1000\n",
      "1200/1200 [==============================] - 1s 850us/step - loss: 0.4017 - accuracy: 0.8797\n",
      "Epoch 560/1000\n",
      "1200/1200 [==============================] - 1s 824us/step - loss: 0.4025 - accuracy: 0.8783\n",
      "Epoch 561/1000\n",
      "1200/1200 [==============================] - 1s 839us/step - loss: 0.4011 - accuracy: 0.8786\n",
      "Epoch 562/1000\n",
      "1200/1200 [==============================] - 1s 848us/step - loss: 0.4015 - accuracy: 0.8798\n",
      "Epoch 563/1000\n",
      "1200/1200 [==============================] - 1s 828us/step - loss: 0.4029 - accuracy: 0.8792\n",
      "Epoch 564/1000\n",
      "1200/1200 [==============================] - 1s 815us/step - loss: 0.4017 - accuracy: 0.8788\n",
      "Epoch 565/1000\n",
      "1200/1200 [==============================] - 1s 859us/step - loss: 0.4027 - accuracy: 0.8790\n",
      "Epoch 566/1000\n",
      "1200/1200 [==============================] - 1s 832us/step - loss: 0.4024 - accuracy: 0.8788\n",
      "Epoch 567/1000\n",
      "1200/1200 [==============================] - 1s 833us/step - loss: 0.4029 - accuracy: 0.8776\n",
      "Epoch 568/1000\n",
      "1200/1200 [==============================] - 1s 840us/step - loss: 0.4029 - accuracy: 0.8781\n",
      "Epoch 569/1000\n",
      "1200/1200 [==============================] - 1s 831us/step - loss: 0.4023 - accuracy: 0.8772\n",
      "Epoch 570/1000\n",
      "1200/1200 [==============================] - 1s 821us/step - loss: 0.4027 - accuracy: 0.8793\n",
      "Epoch 571/1000\n",
      "1200/1200 [==============================] - 1s 841us/step - loss: 0.4023 - accuracy: 0.8788\n",
      "Epoch 572/1000\n",
      "1200/1200 [==============================] - 1s 829us/step - loss: 0.4029 - accuracy: 0.8795\n",
      "Epoch 573/1000\n",
      "1200/1200 [==============================] - 1s 833us/step - loss: 0.4024 - accuracy: 0.8790\n",
      "Epoch 574/1000\n",
      "1200/1200 [==============================] - 1s 824us/step - loss: 0.4028 - accuracy: 0.8778\n",
      "Epoch 575/1000\n",
      "1200/1200 [==============================] - 1s 822us/step - loss: 0.4020 - accuracy: 0.8789\n",
      "Epoch 576/1000\n",
      "1200/1200 [==============================] - 1s 861us/step - loss: 0.4034 - accuracy: 0.8783\n",
      "Epoch 577/1000\n",
      "1200/1200 [==============================] - 1s 828us/step - loss: 0.4030 - accuracy: 0.8782\n",
      "Epoch 578/1000\n",
      "1200/1200 [==============================] - 1s 833us/step - loss: 0.4043 - accuracy: 0.8782\n",
      "Epoch 579/1000\n",
      "1200/1200 [==============================] - 1s 845us/step - loss: 0.4050 - accuracy: 0.8786\n",
      "Epoch 580/1000\n",
      "1200/1200 [==============================] - 1s 822us/step - loss: 0.4042 - accuracy: 0.8794\n",
      "Epoch 581/1000\n",
      "1200/1200 [==============================] - 1s 823us/step - loss: 0.4030 - accuracy: 0.8795\n",
      "Epoch 582/1000\n",
      "1200/1200 [==============================] - 1s 842us/step - loss: 0.4026 - accuracy: 0.8779\n",
      "Epoch 583/1000\n",
      "1200/1200 [==============================] - 1s 819us/step - loss: 0.4031 - accuracy: 0.8795\n",
      "Epoch 584/1000\n",
      "1200/1200 [==============================] - 1s 829us/step - loss: 0.4031 - accuracy: 0.8786\n",
      "Epoch 585/1000\n",
      "1200/1200 [==============================] - 1s 852us/step - loss: 0.4012 - accuracy: 0.8788\n",
      "Epoch 586/1000\n",
      "1200/1200 [==============================] - 1s 818us/step - loss: 0.4042 - accuracy: 0.8790\n",
      "Epoch 587/1000\n",
      "1200/1200 [==============================] - 1s 851us/step - loss: 0.4029 - accuracy: 0.8797\n",
      "Epoch 588/1000\n",
      "1200/1200 [==============================] - 1s 815us/step - loss: 0.4028 - accuracy: 0.8780\n",
      "Epoch 589/1000\n",
      "1200/1200 [==============================] - 1s 822us/step - loss: 0.4031 - accuracy: 0.8777\n",
      "Epoch 590/1000\n",
      "1200/1200 [==============================] - 1s 830us/step - loss: 0.4050 - accuracy: 0.8786\n",
      "Epoch 591/1000\n",
      "1200/1200 [==============================] - 1s 841us/step - loss: 0.4045 - accuracy: 0.8777\n",
      "Epoch 592/1000\n",
      "1200/1200 [==============================] - 1s 825us/step - loss: 0.4037 - accuracy: 0.8784\n",
      "Epoch 593/1000\n",
      "1200/1200 [==============================] - 1s 860us/step - loss: 0.4059 - accuracy: 0.8771\n",
      "Epoch 594/1000\n",
      "1200/1200 [==============================] - 1s 818us/step - loss: 0.4053 - accuracy: 0.8790\n",
      "Epoch 595/1000\n",
      "1200/1200 [==============================] - 1s 826us/step - loss: 0.4035 - accuracy: 0.8783\n",
      "Epoch 596/1000\n",
      "1200/1200 [==============================] - 1s 860us/step - loss: 0.4031 - accuracy: 0.8774\n",
      "Epoch 597/1000\n",
      "1200/1200 [==============================] - 1s 837us/step - loss: 0.4044 - accuracy: 0.8794\n",
      "Epoch 598/1000\n",
      "1200/1200 [==============================] - 1s 855us/step - loss: 0.4036 - accuracy: 0.8796\n",
      "Epoch 599/1000\n",
      "1200/1200 [==============================] - 1s 855us/step - loss: 0.4041 - accuracy: 0.8785\n",
      "Epoch 600/1000\n",
      "1200/1200 [==============================] - 1s 836us/step - loss: 0.4049 - accuracy: 0.8776\n",
      "Epoch 601/1000\n",
      "1200/1200 [==============================] - 1s 844us/step - loss: 0.4038 - accuracy: 0.8773\n",
      "Epoch 602/1000\n",
      "1200/1200 [==============================] - 1s 832us/step - loss: 0.4046 - accuracy: 0.8786\n",
      "Epoch 603/1000\n",
      "1200/1200 [==============================] - 1s 839us/step - loss: 0.4035 - accuracy: 0.8785\n",
      "Epoch 604/1000\n",
      "1200/1200 [==============================] - 1s 864us/step - loss: 0.4041 - accuracy: 0.8786\n",
      "Epoch 605/1000\n",
      "1200/1200 [==============================] - 1s 822us/step - loss: 0.4044 - accuracy: 0.8776\n",
      "Epoch 606/1000\n",
      "1200/1200 [==============================] - 1s 839us/step - loss: 0.4043 - accuracy: 0.8793\n",
      "Epoch 607/1000\n",
      "1200/1200 [==============================] - 1s 843us/step - loss: 0.4046 - accuracy: 0.8786\n",
      "Epoch 608/1000\n",
      "1200/1200 [==============================] - 1s 825us/step - loss: 0.4059 - accuracy: 0.8786\n",
      "Epoch 609/1000\n",
      "1200/1200 [==============================] - 1s 851us/step - loss: 0.4053 - accuracy: 0.8786\n",
      "Epoch 610/1000\n",
      "1200/1200 [==============================] - 1s 833us/step - loss: 0.4043 - accuracy: 0.8784\n",
      "Epoch 611/1000\n",
      "1200/1200 [==============================] - 1s 829us/step - loss: 0.4034 - accuracy: 0.8790\n",
      "Epoch 612/1000\n",
      "1200/1200 [==============================] - 1s 849us/step - loss: 0.4044 - accuracy: 0.8782\n",
      "Epoch 613/1000\n",
      "1200/1200 [==============================] - 1s 829us/step - loss: 0.4047 - accuracy: 0.8794\n",
      "Epoch 614/1000\n",
      "1200/1200 [==============================] - 1s 851us/step - loss: 0.4050 - accuracy: 0.8788\n",
      "Epoch 615/1000\n",
      "1200/1200 [==============================] - 1s 855us/step - loss: 0.4053 - accuracy: 0.8786\n",
      "Epoch 616/1000\n",
      "1200/1200 [==============================] - 1s 817us/step - loss: 0.4029 - accuracy: 0.8792\n",
      "Epoch 617/1000\n",
      "1200/1200 [==============================] - 1s 831us/step - loss: 0.4054 - accuracy: 0.8786\n",
      "Epoch 618/1000\n",
      "1200/1200 [==============================] - 1s 891us/step - loss: 0.4038 - accuracy: 0.8788\n",
      "Epoch 619/1000\n",
      "1200/1200 [==============================] - 1s 838us/step - loss: 0.4051 - accuracy: 0.8801\n",
      "Epoch 620/1000\n",
      "1200/1200 [==============================] - 1s 839us/step - loss: 0.4054 - accuracy: 0.8779\n",
      "Epoch 621/1000\n",
      "1200/1200 [==============================] - 1s 821us/step - loss: 0.4059 - accuracy: 0.8797\n",
      "Epoch 622/1000\n",
      "1200/1200 [==============================] - 1s 829us/step - loss: 0.4047 - accuracy: 0.8784\n",
      "Epoch 623/1000\n",
      "1200/1200 [==============================] - 1s 839us/step - loss: 0.4053 - accuracy: 0.8771\n",
      "Epoch 624/1000\n",
      "1200/1200 [==============================] - 1s 820us/step - loss: 0.4044 - accuracy: 0.8789\n",
      "Epoch 625/1000\n",
      "1200/1200 [==============================] - 1s 819us/step - loss: 0.4066 - accuracy: 0.8782\n",
      "Epoch 626/1000\n",
      "1200/1200 [==============================] - 1s 846us/step - loss: 0.4044 - accuracy: 0.8795\n",
      "Epoch 627/1000\n",
      "1200/1200 [==============================] - 1s 819us/step - loss: 0.4049 - accuracy: 0.8784\n",
      "Epoch 628/1000\n",
      "1200/1200 [==============================] - 1s 849us/step - loss: 0.4051 - accuracy: 0.8789\n",
      "Epoch 629/1000\n",
      "1200/1200 [==============================] - 1s 809us/step - loss: 0.4051 - accuracy: 0.8800\n",
      "Epoch 630/1000\n",
      "1200/1200 [==============================] - 1s 820us/step - loss: 0.4060 - accuracy: 0.8785\n",
      "Epoch 631/1000\n",
      "1200/1200 [==============================] - 1s 839us/step - loss: 0.4047 - accuracy: 0.8788\n",
      "Epoch 632/1000\n",
      "1200/1200 [==============================] - 1s 814us/step - loss: 0.4047 - accuracy: 0.8786\n",
      "Epoch 633/1000\n",
      "1200/1200 [==============================] - 1s 824us/step - loss: 0.4048 - accuracy: 0.8801\n",
      "Epoch 634/1000\n",
      "1200/1200 [==============================] - 1s 848us/step - loss: 0.4044 - accuracy: 0.8790\n",
      "Epoch 635/1000\n",
      "1200/1200 [==============================] - 1s 838us/step - loss: 0.4047 - accuracy: 0.8801\n",
      "Epoch 636/1000\n",
      "1200/1200 [==============================] - 1s 845us/step - loss: 0.4051 - accuracy: 0.8782\n",
      "Epoch 637/1000\n",
      "1200/1200 [==============================] - 1s 834us/step - loss: 0.4048 - accuracy: 0.8784\n",
      "Epoch 638/1000\n",
      "1200/1200 [==============================] - 1s 830us/step - loss: 0.4049 - accuracy: 0.8798\n",
      "Epoch 639/1000\n",
      "1200/1200 [==============================] - 1s 852us/step - loss: 0.4057 - accuracy: 0.8808\n",
      "Epoch 640/1000\n",
      "1200/1200 [==============================] - 1s 836us/step - loss: 0.4051 - accuracy: 0.8780\n",
      "Epoch 641/1000\n",
      "1200/1200 [==============================] - 1s 883us/step - loss: 0.4048 - accuracy: 0.8792\n",
      "Epoch 642/1000\n",
      "1200/1200 [==============================] - 1s 838us/step - loss: 0.4056 - accuracy: 0.8790\n",
      "Epoch 643/1000\n",
      "1200/1200 [==============================] - 1s 849us/step - loss: 0.4050 - accuracy: 0.8785\n",
      "Epoch 644/1000\n",
      "1200/1200 [==============================] - 1s 874us/step - loss: 0.4051 - accuracy: 0.8790\n",
      "Epoch 645/1000\n",
      "1200/1200 [==============================] - 1s 823us/step - loss: 0.4051 - accuracy: 0.8787\n",
      "Epoch 646/1000\n",
      "1200/1200 [==============================] - 1s 828us/step - loss: 0.4058 - accuracy: 0.8787\n",
      "Epoch 647/1000\n",
      "1200/1200 [==============================] - 1s 847us/step - loss: 0.4055 - accuracy: 0.8782\n",
      "Epoch 648/1000\n",
      "1200/1200 [==============================] - 1s 836us/step - loss: 0.4062 - accuracy: 0.8792\n",
      "Epoch 649/1000\n",
      "1200/1200 [==============================] - 1s 846us/step - loss: 0.4047 - accuracy: 0.8785\n",
      "Epoch 650/1000\n",
      "1200/1200 [==============================] - 1s 841us/step - loss: 0.4046 - accuracy: 0.8804\n",
      "Epoch 651/1000\n",
      "1200/1200 [==============================] - 1s 832us/step - loss: 0.4050 - accuracy: 0.8791\n",
      "Epoch 652/1000\n",
      "1200/1200 [==============================] - 1s 857us/step - loss: 0.4049 - accuracy: 0.8775\n",
      "Epoch 653/1000\n",
      "1200/1200 [==============================] - 1s 833us/step - loss: 0.4063 - accuracy: 0.8786\n",
      "Epoch 654/1000\n",
      "1200/1200 [==============================] - 1s 880us/step - loss: 0.4062 - accuracy: 0.8796\n",
      "Epoch 655/1000\n",
      "1200/1200 [==============================] - 1s 823us/step - loss: 0.4059 - accuracy: 0.8790\n",
      "Epoch 656/1000\n",
      "1200/1200 [==============================] - 1s 830us/step - loss: 0.4053 - accuracy: 0.8793\n",
      "Epoch 657/1000\n",
      "1200/1200 [==============================] - 1s 838us/step - loss: 0.4057 - accuracy: 0.8792\n",
      "Epoch 658/1000\n",
      "1200/1200 [==============================] - 1s 828us/step - loss: 0.4057 - accuracy: 0.8783\n",
      "Epoch 659/1000\n",
      "1200/1200 [==============================] - 1s 842us/step - loss: 0.4050 - accuracy: 0.8792\n",
      "Epoch 660/1000\n",
      "1200/1200 [==============================] - 1s 847us/step - loss: 0.4077 - accuracy: 0.8787\n",
      "Epoch 661/1000\n",
      "1200/1200 [==============================] - 1s 826us/step - loss: 0.4054 - accuracy: 0.8785\n",
      "Epoch 662/1000\n",
      "1200/1200 [==============================] - 1s 839us/step - loss: 0.4070 - accuracy: 0.8790\n",
      "Epoch 663/1000\n",
      "1200/1200 [==============================] - 1s 829us/step - loss: 0.4058 - accuracy: 0.8781\n",
      "Epoch 664/1000\n",
      "1200/1200 [==============================] - 1s 820us/step - loss: 0.4079 - accuracy: 0.8783\n",
      "Epoch 665/1000\n",
      "1200/1200 [==============================] - 1s 860us/step - loss: 0.4059 - accuracy: 0.8798\n",
      "Epoch 666/1000\n",
      "1200/1200 [==============================] - 1s 838us/step - loss: 0.4068 - accuracy: 0.8786\n",
      "Epoch 667/1000\n",
      "1200/1200 [==============================] - 1s 845us/step - loss: 0.4069 - accuracy: 0.8787\n",
      "Epoch 668/1000\n",
      "1200/1200 [==============================] - 1s 824us/step - loss: 0.4061 - accuracy: 0.8761\n",
      "Epoch 669/1000\n",
      "1200/1200 [==============================] - 1s 839us/step - loss: 0.4066 - accuracy: 0.8785\n",
      "Epoch 670/1000\n",
      "1200/1200 [==============================] - 1s 870us/step - loss: 0.4048 - accuracy: 0.8776\n",
      "Epoch 671/1000\n",
      "1200/1200 [==============================] - 1s 827us/step - loss: 0.4065 - accuracy: 0.8779\n",
      "Epoch 672/1000\n",
      "1200/1200 [==============================] - 1s 860us/step - loss: 0.4064 - accuracy: 0.8773\n",
      "Epoch 673/1000\n",
      "1200/1200 [==============================] - 1s 830us/step - loss: 0.4052 - accuracy: 0.8791\n",
      "Epoch 674/1000\n",
      "1200/1200 [==============================] - 1s 836us/step - loss: 0.4067 - accuracy: 0.8784\n",
      "Epoch 675/1000\n",
      "1200/1200 [==============================] - 1s 848us/step - loss: 0.4066 - accuracy: 0.8778\n",
      "Epoch 676/1000\n",
      "1200/1200 [==============================] - 1s 838us/step - loss: 0.4074 - accuracy: 0.8784\n",
      "Epoch 677/1000\n",
      "1200/1200 [==============================] - 1s 841us/step - loss: 0.4071 - accuracy: 0.8794\n",
      "Epoch 678/1000\n",
      "1200/1200 [==============================] - 1s 828us/step - loss: 0.4063 - accuracy: 0.8791\n",
      "Epoch 679/1000\n",
      "1200/1200 [==============================] - 1s 858us/step - loss: 0.4063 - accuracy: 0.8797\n",
      "Epoch 680/1000\n",
      "1200/1200 [==============================] - 1s 857us/step - loss: 0.4081 - accuracy: 0.8778\n",
      "Epoch 681/1000\n",
      "1200/1200 [==============================] - 1s 848us/step - loss: 0.4080 - accuracy: 0.8769\n",
      "Epoch 682/1000\n",
      "1200/1200 [==============================] - 1s 850us/step - loss: 0.4078 - accuracy: 0.8775\n",
      "Epoch 683/1000\n",
      "1200/1200 [==============================] - 1s 847us/step - loss: 0.4069 - accuracy: 0.8798\n",
      "Epoch 684/1000\n",
      "1200/1200 [==============================] - 1s 834us/step - loss: 0.4071 - accuracy: 0.8790\n",
      "Epoch 685/1000\n",
      "1200/1200 [==============================] - 1s 867us/step - loss: 0.4068 - accuracy: 0.8791\n",
      "Epoch 686/1000\n",
      "1200/1200 [==============================] - 1s 830us/step - loss: 0.4070 - accuracy: 0.8787\n",
      "Epoch 687/1000\n",
      "1200/1200 [==============================] - 1s 886us/step - loss: 0.4070 - accuracy: 0.8784\n",
      "Epoch 688/1000\n",
      "1200/1200 [==============================] - 1s 833us/step - loss: 0.4077 - accuracy: 0.8792\n",
      "Epoch 689/1000\n",
      "1200/1200 [==============================] - 1s 837us/step - loss: 0.4075 - accuracy: 0.8786\n",
      "Epoch 690/1000\n",
      "1200/1200 [==============================] - 1s 843us/step - loss: 0.4064 - accuracy: 0.8815\n",
      "Epoch 691/1000\n",
      "1200/1200 [==============================] - 1s 833us/step - loss: 0.4062 - accuracy: 0.8787\n",
      "Epoch 692/1000\n",
      "1200/1200 [==============================] - 1s 825us/step - loss: 0.4057 - accuracy: 0.8786\n",
      "Epoch 693/1000\n",
      "1200/1200 [==============================] - 1s 857us/step - loss: 0.4065 - accuracy: 0.8778\n",
      "Epoch 694/1000\n",
      "1200/1200 [==============================] - 1s 823us/step - loss: 0.4075 - accuracy: 0.8792\n",
      "Epoch 695/1000\n",
      "1200/1200 [==============================] - 1s 851us/step - loss: 0.4102 - accuracy: 0.8783\n",
      "Epoch 696/1000\n",
      "1200/1200 [==============================] - 1s 828us/step - loss: 0.4065 - accuracy: 0.8788\n",
      "Epoch 697/1000\n",
      "1200/1200 [==============================] - 1s 825us/step - loss: 0.4065 - accuracy: 0.8793\n",
      "Epoch 698/1000\n",
      "1200/1200 [==============================] - 1s 858us/step - loss: 0.4068 - accuracy: 0.8785\n",
      "Epoch 699/1000\n",
      "1200/1200 [==============================] - 1s 822us/step - loss: 0.4095 - accuracy: 0.8787\n",
      "Epoch 700/1000\n",
      "1200/1200 [==============================] - 1s 858us/step - loss: 0.4077 - accuracy: 0.8792\n",
      "Epoch 701/1000\n",
      "1200/1200 [==============================] - 1s 827us/step - loss: 0.4073 - accuracy: 0.8785\n",
      "Epoch 702/1000\n",
      "1200/1200 [==============================] - 1s 838us/step - loss: 0.4088 - accuracy: 0.8791\n",
      "Epoch 703/1000\n",
      "1200/1200 [==============================] - 1s 845us/step - loss: 0.4072 - accuracy: 0.8784\n",
      "Epoch 704/1000\n",
      "1200/1200 [==============================] - 1s 840us/step - loss: 0.4076 - accuracy: 0.8788\n",
      "Epoch 705/1000\n",
      "1200/1200 [==============================] - 1s 824us/step - loss: 0.4080 - accuracy: 0.8771\n",
      "Epoch 706/1000\n",
      "1200/1200 [==============================] - 1s 859us/step - loss: 0.4070 - accuracy: 0.8790\n",
      "Epoch 707/1000\n",
      "1200/1200 [==============================] - 1s 837us/step - loss: 0.4073 - accuracy: 0.8784\n",
      "Epoch 708/1000\n",
      "1200/1200 [==============================] - 1s 854us/step - loss: 0.4068 - accuracy: 0.8793\n",
      "Epoch 709/1000\n",
      "1200/1200 [==============================] - 1s 835us/step - loss: 0.4065 - accuracy: 0.8793\n",
      "Epoch 710/1000\n",
      "1200/1200 [==============================] - 1s 822us/step - loss: 0.4068 - accuracy: 0.8791\n",
      "Epoch 711/1000\n",
      "1200/1200 [==============================] - 1s 857us/step - loss: 0.4082 - accuracy: 0.8773\n",
      "Epoch 712/1000\n",
      "1200/1200 [==============================] - 1s 825us/step - loss: 0.4074 - accuracy: 0.8783\n",
      "Epoch 713/1000\n",
      "1200/1200 [==============================] - 1s 855us/step - loss: 0.4072 - accuracy: 0.8793\n",
      "Epoch 714/1000\n",
      "1200/1200 [==============================] - 1s 827us/step - loss: 0.4072 - accuracy: 0.8791\n",
      "Epoch 715/1000\n",
      "1200/1200 [==============================] - 1s 852us/step - loss: 0.4077 - accuracy: 0.8772\n",
      "Epoch 716/1000\n",
      "1200/1200 [==============================] - 1s 828us/step - loss: 0.4061 - accuracy: 0.8795\n",
      "Epoch 717/1000\n",
      "1200/1200 [==============================] - 1s 830us/step - loss: 0.4090 - accuracy: 0.8782\n",
      "Epoch 718/1000\n",
      "1200/1200 [==============================] - 1s 845us/step - loss: 0.4082 - accuracy: 0.8796\n",
      "Epoch 719/1000\n",
      "1200/1200 [==============================] - 1s 849us/step - loss: 0.4092 - accuracy: 0.8788\n",
      "Epoch 720/1000\n",
      "1200/1200 [==============================] - 1s 857us/step - loss: 0.4081 - accuracy: 0.8799\n",
      "Epoch 721/1000\n",
      "1200/1200 [==============================] - 1s 841us/step - loss: 0.4096 - accuracy: 0.8789\n",
      "Epoch 722/1000\n",
      "1200/1200 [==============================] - 1s 834us/step - loss: 0.4068 - accuracy: 0.8787\n",
      "Epoch 723/1000\n",
      "1200/1200 [==============================] - 1s 847us/step - loss: 0.4093 - accuracy: 0.8785\n",
      "Epoch 724/1000\n",
      "1200/1200 [==============================] - 1s 831us/step - loss: 0.4080 - accuracy: 0.8792\n",
      "Epoch 725/1000\n",
      "1200/1200 [==============================] - 1s 831us/step - loss: 0.4080 - accuracy: 0.8796\n",
      "Epoch 726/1000\n",
      "1200/1200 [==============================] - 1s 837us/step - loss: 0.4078 - accuracy: 0.8801\n",
      "Epoch 727/1000\n",
      "1200/1200 [==============================] - 1s 823us/step - loss: 0.4077 - accuracy: 0.8801\n",
      "Epoch 728/1000\n",
      "1200/1200 [==============================] - 1s 855us/step - loss: 0.4076 - accuracy: 0.8803\n",
      "Epoch 729/1000\n",
      "1200/1200 [==============================] - 1s 822us/step - loss: 0.4080 - accuracy: 0.8785\n",
      "Epoch 730/1000\n",
      "1200/1200 [==============================] - 1s 855us/step - loss: 0.4082 - accuracy: 0.8780\n",
      "Epoch 731/1000\n",
      "1200/1200 [==============================] - 1s 831us/step - loss: 0.4082 - accuracy: 0.8801\n",
      "Epoch 732/1000\n",
      "1200/1200 [==============================] - 1s 817us/step - loss: 0.4090 - accuracy: 0.8791\n",
      "Epoch 733/1000\n",
      "1200/1200 [==============================] - 1s 861us/step - loss: 0.4072 - accuracy: 0.8804\n",
      "Epoch 734/1000\n",
      "1200/1200 [==============================] - 1s 828us/step - loss: 0.4096 - accuracy: 0.8789\n",
      "Epoch 735/1000\n",
      "1200/1200 [==============================] - 1s 862us/step - loss: 0.4081 - accuracy: 0.8793\n",
      "Epoch 736/1000\n",
      "1200/1200 [==============================] - 1s 829us/step - loss: 0.4095 - accuracy: 0.8790\n",
      "Epoch 737/1000\n",
      "1200/1200 [==============================] - 1s 841us/step - loss: 0.4095 - accuracy: 0.8797\n",
      "Epoch 738/1000\n",
      "1200/1200 [==============================] - 1s 859us/step - loss: 0.4107 - accuracy: 0.8792\n",
      "Epoch 739/1000\n",
      "1200/1200 [==============================] - 1s 846us/step - loss: 0.4081 - accuracy: 0.8779\n",
      "Epoch 740/1000\n",
      "1200/1200 [==============================] - 1s 851us/step - loss: 0.4093 - accuracy: 0.8797\n",
      "Epoch 741/1000\n",
      "1200/1200 [==============================] - 1s 844us/step - loss: 0.4090 - accuracy: 0.8794\n",
      "Epoch 742/1000\n",
      "1200/1200 [==============================] - 1s 847us/step - loss: 0.4074 - accuracy: 0.8799\n",
      "Epoch 743/1000\n",
      "1200/1200 [==============================] - 1s 835us/step - loss: 0.4094 - accuracy: 0.8786\n",
      "Epoch 744/1000\n",
      "1200/1200 [==============================] - 1s 840us/step - loss: 0.4080 - accuracy: 0.8789\n",
      "Epoch 745/1000\n",
      "1200/1200 [==============================] - 1s 832us/step - loss: 0.4110 - accuracy: 0.8785\n",
      "Epoch 746/1000\n",
      "1200/1200 [==============================] - 1s 841us/step - loss: 0.4091 - accuracy: 0.8772\n",
      "Epoch 747/1000\n",
      "1200/1200 [==============================] - 1s 841us/step - loss: 0.4083 - accuracy: 0.8782\n",
      "Epoch 748/1000\n",
      "1200/1200 [==============================] - 1s 824us/step - loss: 0.4086 - accuracy: 0.8791\n",
      "Epoch 749/1000\n",
      "1200/1200 [==============================] - 1s 839us/step - loss: 0.4096 - accuracy: 0.8795\n",
      "Epoch 750/1000\n",
      "1200/1200 [==============================] - 1s 833us/step - loss: 0.4097 - accuracy: 0.8797\n",
      "Epoch 751/1000\n",
      "1200/1200 [==============================] - 1s 843us/step - loss: 0.4106 - accuracy: 0.8791\n",
      "Epoch 752/1000\n",
      "1200/1200 [==============================] - 1s 828us/step - loss: 0.4093 - accuracy: 0.8788\n",
      "Epoch 753/1000\n",
      "1200/1200 [==============================] - 1s 816us/step - loss: 0.4104 - accuracy: 0.8795\n",
      "Epoch 754/1000\n",
      "1200/1200 [==============================] - 1s 866us/step - loss: 0.4098 - accuracy: 0.8796\n",
      "Epoch 755/1000\n",
      "1200/1200 [==============================] - 1s 819us/step - loss: 0.4112 - accuracy: 0.8778\n",
      "Epoch 756/1000\n",
      "1200/1200 [==============================] - 1s 847us/step - loss: 0.4106 - accuracy: 0.8793\n",
      "Epoch 757/1000\n",
      "1200/1200 [==============================] - 1s 821us/step - loss: 0.4100 - accuracy: 0.8800\n",
      "Epoch 758/1000\n",
      "1200/1200 [==============================] - 1s 854us/step - loss: 0.4092 - accuracy: 0.8788\n",
      "Epoch 759/1000\n",
      "1200/1200 [==============================] - 1s 831us/step - loss: 0.4091 - accuracy: 0.8794\n",
      "Epoch 760/1000\n",
      "1200/1200 [==============================] - 1s 835us/step - loss: 0.4084 - accuracy: 0.8783\n",
      "Epoch 761/1000\n",
      "1200/1200 [==============================] - 1s 833us/step - loss: 0.4101 - accuracy: 0.8796\n",
      "Epoch 762/1000\n",
      "1200/1200 [==============================] - 1s 812us/step - loss: 0.4107 - accuracy: 0.8777\n",
      "Epoch 763/1000\n",
      "1200/1200 [==============================] - 1s 859us/step - loss: 0.4091 - accuracy: 0.8785\n",
      "Epoch 764/1000\n",
      "1200/1200 [==============================] - 1s 826us/step - loss: 0.4104 - accuracy: 0.8782\n",
      "Epoch 765/1000\n",
      "1200/1200 [==============================] - 1s 861us/step - loss: 0.4103 - accuracy: 0.8793\n",
      "Epoch 766/1000\n",
      "1200/1200 [==============================] - 1s 821us/step - loss: 0.4097 - accuracy: 0.8801\n",
      "Epoch 767/1000\n",
      "1200/1200 [==============================] - 1s 835us/step - loss: 0.4112 - accuracy: 0.8800\n",
      "Epoch 768/1000\n",
      "1200/1200 [==============================] - 1s 849us/step - loss: 0.4098 - accuracy: 0.8799\n",
      "Epoch 769/1000\n",
      "1200/1200 [==============================] - 1s 853us/step - loss: 0.4092 - accuracy: 0.8794\n",
      "Epoch 770/1000\n",
      "1200/1200 [==============================] - 1s 852us/step - loss: 0.4114 - accuracy: 0.8791\n",
      "Epoch 771/1000\n",
      "1200/1200 [==============================] - 1s 834us/step - loss: 0.4109 - accuracy: 0.8802\n",
      "Epoch 772/1000\n",
      "1200/1200 [==============================] - 1s 831us/step - loss: 0.4112 - accuracy: 0.8779\n",
      "Epoch 773/1000\n",
      "1200/1200 [==============================] - 1s 845us/step - loss: 0.4105 - accuracy: 0.8799\n",
      "Epoch 774/1000\n",
      "1200/1200 [==============================] - 1s 872us/step - loss: 0.4104 - accuracy: 0.8801\n",
      "Epoch 775/1000\n",
      "1200/1200 [==============================] - 1s 843us/step - loss: 0.4110 - accuracy: 0.8798\n",
      "Epoch 776/1000\n",
      "1200/1200 [==============================] - 1s 834us/step - loss: 0.4112 - accuracy: 0.8804\n",
      "Epoch 777/1000\n",
      "1200/1200 [==============================] - 1s 850us/step - loss: 0.4113 - accuracy: 0.8780\n",
      "Epoch 778/1000\n",
      "1200/1200 [==============================] - 1s 834us/step - loss: 0.4092 - accuracy: 0.8794\n",
      "Epoch 779/1000\n",
      "1200/1200 [==============================] - 1s 819us/step - loss: 0.4116 - accuracy: 0.8780\n",
      "Epoch 780/1000\n",
      "1200/1200 [==============================] - 1s 865us/step - loss: 0.4119 - accuracy: 0.8797\n",
      "Epoch 781/1000\n",
      "1200/1200 [==============================] - 1s 827us/step - loss: 0.4116 - accuracy: 0.8791\n",
      "Epoch 782/1000\n",
      "1200/1200 [==============================] - 1s 869us/step - loss: 0.4125 - accuracy: 0.8793\n",
      "Epoch 783/1000\n",
      "1200/1200 [==============================] - 1s 837us/step - loss: 0.4148 - accuracy: 0.8789\n",
      "Epoch 784/1000\n",
      "1200/1200 [==============================] - 1s 877us/step - loss: 0.4127 - accuracy: 0.8779\n",
      "Epoch 785/1000\n",
      "1200/1200 [==============================] - 1s 849us/step - loss: 0.4128 - accuracy: 0.8788\n",
      "Epoch 786/1000\n",
      "1200/1200 [==============================] - 1s 857us/step - loss: 0.4120 - accuracy: 0.8788\n",
      "Epoch 787/1000\n",
      "1200/1200 [==============================] - 1s 870us/step - loss: 0.4121 - accuracy: 0.8796\n",
      "Epoch 788/1000\n",
      "1200/1200 [==============================] - 1s 825us/step - loss: 0.4111 - accuracy: 0.8795\n",
      "Epoch 789/1000\n",
      "1200/1200 [==============================] - 1s 868us/step - loss: 0.4128 - accuracy: 0.8791\n",
      "Epoch 790/1000\n",
      "1200/1200 [==============================] - 1s 858us/step - loss: 0.4117 - accuracy: 0.8789\n",
      "Epoch 791/1000\n",
      "1200/1200 [==============================] - 1s 858us/step - loss: 0.4118 - accuracy: 0.8793\n",
      "Epoch 792/1000\n",
      "1200/1200 [==============================] - 1s 823us/step - loss: 0.4114 - accuracy: 0.8791\n",
      "Epoch 793/1000\n",
      "1200/1200 [==============================] - 1s 840us/step - loss: 0.4122 - accuracy: 0.8800\n",
      "Epoch 794/1000\n",
      "1200/1200 [==============================] - 1s 850us/step - loss: 0.4122 - accuracy: 0.8799\n",
      "Epoch 795/1000\n",
      "1200/1200 [==============================] - 1s 831us/step - loss: 0.4128 - accuracy: 0.8786\n",
      "Epoch 796/1000\n",
      "1200/1200 [==============================] - 1s 857us/step - loss: 0.4126 - accuracy: 0.8794\n",
      "Epoch 797/1000\n",
      "1200/1200 [==============================] - 1s 841us/step - loss: 0.4130 - accuracy: 0.8786\n",
      "Epoch 798/1000\n",
      "1200/1200 [==============================] - 1s 861us/step - loss: 0.4131 - accuracy: 0.8799\n",
      "Epoch 799/1000\n",
      "1200/1200 [==============================] - 1s 871us/step - loss: 0.4121 - accuracy: 0.8790\n",
      "Epoch 800/1000\n",
      "1200/1200 [==============================] - 1s 852us/step - loss: 0.4107 - accuracy: 0.8785\n",
      "Epoch 801/1000\n",
      "1200/1200 [==============================] - 1s 830us/step - loss: 0.4114 - accuracy: 0.8798\n",
      "Epoch 802/1000\n",
      "1200/1200 [==============================] - 1s 836us/step - loss: 0.4114 - accuracy: 0.8783\n",
      "Epoch 803/1000\n",
      "1200/1200 [==============================] - 1s 849us/step - loss: 0.4124 - accuracy: 0.8782\n",
      "Epoch 804/1000\n",
      "1200/1200 [==============================] - 1s 861us/step - loss: 0.4130 - accuracy: 0.8796\n",
      "Epoch 805/1000\n",
      "1200/1200 [==============================] - 1s 885us/step - loss: 0.4120 - accuracy: 0.8785\n",
      "Epoch 806/1000\n",
      "1200/1200 [==============================] - 1s 860us/step - loss: 0.4123 - accuracy: 0.8797\n",
      "Epoch 807/1000\n",
      "1200/1200 [==============================] - 1s 893us/step - loss: 0.4124 - accuracy: 0.8780\n",
      "Epoch 808/1000\n",
      "1200/1200 [==============================] - 1s 878us/step - loss: 0.4116 - accuracy: 0.8796\n",
      "Epoch 809/1000\n",
      "1200/1200 [==============================] - 1s 869us/step - loss: 0.4123 - accuracy: 0.8792\n",
      "Epoch 810/1000\n",
      "1200/1200 [==============================] - 1s 837us/step - loss: 0.4131 - accuracy: 0.8797\n",
      "Epoch 811/1000\n",
      "1200/1200 [==============================] - 1s 861us/step - loss: 0.4129 - accuracy: 0.8779\n",
      "Epoch 812/1000\n",
      "1200/1200 [==============================] - 1s 826us/step - loss: 0.4134 - accuracy: 0.8786\n",
      "Epoch 813/1000\n",
      "1200/1200 [==============================] - 1s 843us/step - loss: 0.4115 - accuracy: 0.8801\n",
      "Epoch 814/1000\n",
      "1200/1200 [==============================] - 1s 833us/step - loss: 0.4106 - accuracy: 0.8791\n",
      "Epoch 815/1000\n",
      "1200/1200 [==============================] - 1s 827us/step - loss: 0.4135 - accuracy: 0.8790\n",
      "Epoch 816/1000\n",
      "1200/1200 [==============================] - 1s 848us/step - loss: 0.4127 - accuracy: 0.8775\n",
      "Epoch 817/1000\n",
      "1200/1200 [==============================] - 1s 836us/step - loss: 0.4109 - accuracy: 0.8797\n",
      "Epoch 818/1000\n",
      "1200/1200 [==============================] - 1s 853us/step - loss: 0.4118 - accuracy: 0.8797\n",
      "Epoch 819/1000\n",
      "1200/1200 [==============================] - 1s 834us/step - loss: 0.4119 - accuracy: 0.8789\n",
      "Epoch 820/1000\n",
      "1200/1200 [==============================] - 1s 846us/step - loss: 0.4131 - accuracy: 0.8785\n",
      "Epoch 821/1000\n",
      "1200/1200 [==============================] - 1s 834us/step - loss: 0.4128 - accuracy: 0.8788\n",
      "Epoch 822/1000\n",
      "1200/1200 [==============================] - 1s 850us/step - loss: 0.4130 - accuracy: 0.8794\n",
      "Epoch 823/1000\n",
      "1200/1200 [==============================] - 1s 840us/step - loss: 0.4137 - accuracy: 0.8778\n",
      "Epoch 824/1000\n",
      "1200/1200 [==============================] - 1s 840us/step - loss: 0.4119 - accuracy: 0.8809\n",
      "Epoch 825/1000\n",
      "1200/1200 [==============================] - 1s 833us/step - loss: 0.4101 - accuracy: 0.8784\n",
      "Epoch 826/1000\n",
      "1200/1200 [==============================] - 1s 840us/step - loss: 0.4134 - accuracy: 0.8803\n",
      "Epoch 827/1000\n",
      "1200/1200 [==============================] - 1s 834us/step - loss: 0.4128 - accuracy: 0.8782\n",
      "Epoch 828/1000\n",
      "1200/1200 [==============================] - 1s 836us/step - loss: 0.4128 - accuracy: 0.8798\n",
      "Epoch 829/1000\n",
      "1200/1200 [==============================] - 1s 846us/step - loss: 0.4132 - accuracy: 0.8809\n",
      "Epoch 830/1000\n",
      "1200/1200 [==============================] - 1s 847us/step - loss: 0.4130 - accuracy: 0.8776\n",
      "Epoch 831/1000\n",
      "1200/1200 [==============================] - 1s 861us/step - loss: 0.4124 - accuracy: 0.8789\n",
      "Epoch 832/1000\n",
      "1200/1200 [==============================] - 1s 847us/step - loss: 0.4122 - accuracy: 0.8786\n",
      "Epoch 833/1000\n",
      "1200/1200 [==============================] - 1s 861us/step - loss: 0.4127 - accuracy: 0.8783\n",
      "Epoch 834/1000\n",
      "1200/1200 [==============================] - 1s 861us/step - loss: 0.4133 - accuracy: 0.8780\n",
      "Epoch 835/1000\n",
      "1200/1200 [==============================] - 1s 855us/step - loss: 0.4115 - accuracy: 0.8793\n",
      "Epoch 836/1000\n",
      "1200/1200 [==============================] - 1s 845us/step - loss: 0.4138 - accuracy: 0.8778\n",
      "Epoch 837/1000\n",
      "1200/1200 [==============================] - 1s 848us/step - loss: 0.4134 - accuracy: 0.8784\n",
      "Epoch 838/1000\n",
      "1200/1200 [==============================] - 1s 836us/step - loss: 0.4136 - accuracy: 0.8786\n",
      "Epoch 839/1000\n",
      "1200/1200 [==============================] - 1s 852us/step - loss: 0.4139 - accuracy: 0.8793\n",
      "Epoch 840/1000\n",
      "1200/1200 [==============================] - 1s 833us/step - loss: 0.4128 - accuracy: 0.8811\n",
      "Epoch 841/1000\n",
      "1200/1200 [==============================] - 1s 831us/step - loss: 0.4135 - accuracy: 0.8779\n",
      "Epoch 842/1000\n",
      "1200/1200 [==============================] - 1s 864us/step - loss: 0.4126 - accuracy: 0.8792\n",
      "Epoch 843/1000\n",
      "1200/1200 [==============================] - 1s 863us/step - loss: 0.4143 - accuracy: 0.8797\n",
      "Epoch 844/1000\n",
      "1200/1200 [==============================] - 1s 879us/step - loss: 0.4131 - accuracy: 0.8807\n",
      "Epoch 845/1000\n",
      "1200/1200 [==============================] - 1s 849us/step - loss: 0.4137 - accuracy: 0.8790\n",
      "Epoch 846/1000\n",
      "1200/1200 [==============================] - 1s 867us/step - loss: 0.4135 - accuracy: 0.8807\n",
      "Epoch 847/1000\n",
      "1200/1200 [==============================] - 1s 848us/step - loss: 0.4131 - accuracy: 0.8783\n",
      "Epoch 848/1000\n",
      "1200/1200 [==============================] - 1s 857us/step - loss: 0.4138 - accuracy: 0.8792\n",
      "Epoch 849/1000\n",
      "1200/1200 [==============================] - 1s 832us/step - loss: 0.4134 - accuracy: 0.8806\n",
      "Epoch 850/1000\n",
      "1200/1200 [==============================] - 1s 829us/step - loss: 0.4140 - accuracy: 0.8789\n",
      "Epoch 851/1000\n",
      "1200/1200 [==============================] - 1s 856us/step - loss: 0.4138 - accuracy: 0.8793\n",
      "Epoch 852/1000\n",
      "1200/1200 [==============================] - 1s 823us/step - loss: 0.4137 - accuracy: 0.8804\n",
      "Epoch 853/1000\n",
      "1200/1200 [==============================] - 1s 854us/step - loss: 0.4151 - accuracy: 0.8803\n",
      "Epoch 854/1000\n",
      "1200/1200 [==============================] - 1s 828us/step - loss: 0.4156 - accuracy: 0.8797\n",
      "Epoch 855/1000\n",
      "1200/1200 [==============================] - 1s 860us/step - loss: 0.4147 - accuracy: 0.8790\n",
      "Epoch 856/1000\n",
      "1200/1200 [==============================] - 1s 832us/step - loss: 0.4130 - accuracy: 0.8788\n",
      "Epoch 857/1000\n",
      "1200/1200 [==============================] - 1s 856us/step - loss: 0.4140 - accuracy: 0.8787\n",
      "Epoch 858/1000\n",
      "1200/1200 [==============================] - 1s 833us/step - loss: 0.4146 - accuracy: 0.8796\n",
      "Epoch 859/1000\n",
      "1200/1200 [==============================] - 1s 863us/step - loss: 0.4151 - accuracy: 0.8791\n",
      "Epoch 860/1000\n",
      "1200/1200 [==============================] - 1s 837us/step - loss: 0.4132 - accuracy: 0.8804\n",
      "Epoch 861/1000\n",
      "1200/1200 [==============================] - 1s 853us/step - loss: 0.4145 - accuracy: 0.8790\n",
      "Epoch 862/1000\n",
      "1200/1200 [==============================] - 1s 837us/step - loss: 0.4149 - accuracy: 0.8789\n",
      "Epoch 863/1000\n",
      "1200/1200 [==============================] - 1s 856us/step - loss: 0.4158 - accuracy: 0.8792\n",
      "Epoch 864/1000\n",
      "1200/1200 [==============================] - 1s 846us/step - loss: 0.4156 - accuracy: 0.8781\n",
      "Epoch 865/1000\n",
      "1200/1200 [==============================] - 1s 862us/step - loss: 0.4170 - accuracy: 0.8801\n",
      "Epoch 866/1000\n",
      "1200/1200 [==============================] - 1s 850us/step - loss: 0.4146 - accuracy: 0.8794\n",
      "Epoch 867/1000\n",
      "1200/1200 [==============================] - 1s 854us/step - loss: 0.4129 - accuracy: 0.8793\n",
      "Epoch 868/1000\n",
      "1200/1200 [==============================] - 1s 843us/step - loss: 0.4157 - accuracy: 0.8790\n",
      "Epoch 869/1000\n",
      "1200/1200 [==============================] - 1s 829us/step - loss: 0.4135 - accuracy: 0.8792\n",
      "Epoch 870/1000\n",
      "1200/1200 [==============================] - 1s 855us/step - loss: 0.4148 - accuracy: 0.8799\n",
      "Epoch 871/1000\n",
      "1200/1200 [==============================] - 1s 846us/step - loss: 0.4150 - accuracy: 0.8802\n",
      "Epoch 872/1000\n",
      "1200/1200 [==============================] - 1s 861us/step - loss: 0.4141 - accuracy: 0.8802\n",
      "Epoch 873/1000\n",
      "1200/1200 [==============================] - 1s 840us/step - loss: 0.4145 - accuracy: 0.8801\n",
      "Epoch 874/1000\n",
      "1200/1200 [==============================] - 1s 852us/step - loss: 0.4158 - accuracy: 0.8795\n",
      "Epoch 875/1000\n",
      "1200/1200 [==============================] - 1s 851us/step - loss: 0.4140 - accuracy: 0.8796\n",
      "Epoch 876/1000\n",
      "1200/1200 [==============================] - 1s 852us/step - loss: 0.4150 - accuracy: 0.8804\n",
      "Epoch 877/1000\n",
      "1200/1200 [==============================] - 1s 839us/step - loss: 0.4146 - accuracy: 0.8803\n",
      "Epoch 878/1000\n",
      "1200/1200 [==============================] - 1s 847us/step - loss: 0.4159 - accuracy: 0.8779\n",
      "Epoch 879/1000\n",
      "1200/1200 [==============================] - 1s 837us/step - loss: 0.4144 - accuracy: 0.8793\n",
      "Epoch 880/1000\n",
      "1200/1200 [==============================] - 1s 867us/step - loss: 0.4161 - accuracy: 0.8783\n",
      "Epoch 881/1000\n",
      "1200/1200 [==============================] - 1s 839us/step - loss: 0.4173 - accuracy: 0.8795\n",
      "Epoch 882/1000\n",
      "1200/1200 [==============================] - 1s 853us/step - loss: 0.4158 - accuracy: 0.8799\n",
      "Epoch 883/1000\n",
      "1200/1200 [==============================] - 1s 849us/step - loss: 0.4159 - accuracy: 0.8795\n",
      "Epoch 884/1000\n",
      "1200/1200 [==============================] - 1s 860us/step - loss: 0.4165 - accuracy: 0.8786\n",
      "Epoch 885/1000\n",
      "1200/1200 [==============================] - 1s 832us/step - loss: 0.4166 - accuracy: 0.8778\n",
      "Epoch 886/1000\n",
      "1200/1200 [==============================] - 1s 850us/step - loss: 0.4147 - accuracy: 0.8789\n",
      "Epoch 887/1000\n",
      "1200/1200 [==============================] - 1s 843us/step - loss: 0.4161 - accuracy: 0.8783\n",
      "Epoch 888/1000\n",
      "1200/1200 [==============================] - 1s 856us/step - loss: 0.4140 - accuracy: 0.8800\n",
      "Epoch 889/1000\n",
      "1200/1200 [==============================] - 1s 852us/step - loss: 0.4135 - accuracy: 0.8798\n",
      "Epoch 890/1000\n",
      "1200/1200 [==============================] - 1s 836us/step - loss: 0.4149 - accuracy: 0.8803\n",
      "Epoch 891/1000\n",
      "1200/1200 [==============================] - 1s 855us/step - loss: 0.4158 - accuracy: 0.8784\n",
      "Epoch 892/1000\n",
      "1200/1200 [==============================] - 1s 843us/step - loss: 0.4146 - accuracy: 0.8799\n",
      "Epoch 893/1000\n",
      "1200/1200 [==============================] - 1s 868us/step - loss: 0.4141 - accuracy: 0.8787\n",
      "Epoch 894/1000\n",
      "1200/1200 [==============================] - 1s 879us/step - loss: 0.4151 - accuracy: 0.8801\n",
      "Epoch 895/1000\n",
      "1200/1200 [==============================] - 1s 846us/step - loss: 0.4141 - accuracy: 0.8786\n",
      "Epoch 896/1000\n",
      "1200/1200 [==============================] - 1s 833us/step - loss: 0.4158 - accuracy: 0.8786\n",
      "Epoch 897/1000\n",
      "1200/1200 [==============================] - 1s 866us/step - loss: 0.4145 - accuracy: 0.8795\n",
      "Epoch 898/1000\n",
      "1200/1200 [==============================] - 1s 829us/step - loss: 0.4156 - accuracy: 0.8789\n",
      "Epoch 899/1000\n",
      "1200/1200 [==============================] - 1s 853us/step - loss: 0.4156 - accuracy: 0.8786\n",
      "Epoch 900/1000\n",
      "1200/1200 [==============================] - 1s 837us/step - loss: 0.4168 - accuracy: 0.8780\n",
      "Epoch 901/1000\n",
      "1200/1200 [==============================] - 1s 863us/step - loss: 0.4160 - accuracy: 0.8790\n",
      "Epoch 902/1000\n",
      "1200/1200 [==============================] - 1s 832us/step - loss: 0.4159 - accuracy: 0.8805\n",
      "Epoch 903/1000\n",
      "1200/1200 [==============================] - 1s 869us/step - loss: 0.4162 - accuracy: 0.8782\n",
      "Epoch 904/1000\n",
      "1200/1200 [==============================] - 1s 847us/step - loss: 0.4163 - accuracy: 0.8772\n",
      "Epoch 905/1000\n",
      "1200/1200 [==============================] - 1s 874us/step - loss: 0.4176 - accuracy: 0.8793\n",
      "Epoch 906/1000\n",
      "1200/1200 [==============================] - 1s 819us/step - loss: 0.4164 - accuracy: 0.8786\n",
      "Epoch 907/1000\n",
      "1200/1200 [==============================] - 1s 862us/step - loss: 0.4154 - accuracy: 0.8797\n",
      "Epoch 908/1000\n",
      "1200/1200 [==============================] - 1s 827us/step - loss: 0.4144 - accuracy: 0.8787\n",
      "Epoch 909/1000\n",
      "1200/1200 [==============================] - 1s 894us/step - loss: 0.4156 - accuracy: 0.8789\n",
      "Epoch 910/1000\n",
      "1200/1200 [==============================] - 1s 837us/step - loss: 0.4167 - accuracy: 0.8795\n",
      "Epoch 911/1000\n",
      "1200/1200 [==============================] - 1s 863us/step - loss: 0.4161 - accuracy: 0.8784\n",
      "Epoch 912/1000\n",
      "1200/1200 [==============================] - 1s 834us/step - loss: 0.4162 - accuracy: 0.8801\n",
      "Epoch 913/1000\n",
      "1200/1200 [==============================] - 1s 860us/step - loss: 0.4168 - accuracy: 0.8784\n",
      "Epoch 914/1000\n",
      "1200/1200 [==============================] - 1s 832us/step - loss: 0.4159 - accuracy: 0.8788\n",
      "Epoch 915/1000\n",
      "1200/1200 [==============================] - 1s 854us/step - loss: 0.4164 - accuracy: 0.8784\n",
      "Epoch 916/1000\n",
      "1200/1200 [==============================] - 1s 831us/step - loss: 0.4166 - accuracy: 0.8786\n",
      "Epoch 917/1000\n",
      "1200/1200 [==============================] - 1s 851us/step - loss: 0.4167 - accuracy: 0.8795\n",
      "Epoch 918/1000\n",
      "1200/1200 [==============================] - 1s 857us/step - loss: 0.4157 - accuracy: 0.8790\n",
      "Epoch 919/1000\n",
      "1200/1200 [==============================] - 1s 868us/step - loss: 0.4163 - accuracy: 0.8792\n",
      "Epoch 920/1000\n",
      "1200/1200 [==============================] - 1s 857us/step - loss: 0.4156 - accuracy: 0.8797\n",
      "Epoch 921/1000\n",
      "1200/1200 [==============================] - 1s 872us/step - loss: 0.4171 - accuracy: 0.8779\n",
      "Epoch 922/1000\n",
      "1200/1200 [==============================] - 1s 847us/step - loss: 0.4166 - accuracy: 0.8803\n",
      "Epoch 923/1000\n",
      "1200/1200 [==============================] - 1s 864us/step - loss: 0.4174 - accuracy: 0.8792\n",
      "Epoch 924/1000\n",
      "1200/1200 [==============================] - 1s 855us/step - loss: 0.4174 - accuracy: 0.8799\n",
      "Epoch 925/1000\n",
      "1200/1200 [==============================] - 1s 887us/step - loss: 0.4165 - accuracy: 0.8793\n",
      "Epoch 926/1000\n",
      "1200/1200 [==============================] - 1s 855us/step - loss: 0.4177 - accuracy: 0.8804\n",
      "Epoch 927/1000\n",
      "1200/1200 [==============================] - 1s 874us/step - loss: 0.4164 - accuracy: 0.8797\n",
      "Epoch 928/1000\n",
      "1200/1200 [==============================] - 1s 871us/step - loss: 0.4169 - accuracy: 0.8792\n",
      "Epoch 929/1000\n",
      "1200/1200 [==============================] - 1s 884us/step - loss: 0.4164 - accuracy: 0.8794\n",
      "Epoch 930/1000\n",
      "1200/1200 [==============================] - 1s 868us/step - loss: 0.4184 - accuracy: 0.8772\n",
      "Epoch 931/1000\n",
      "1200/1200 [==============================] - 1s 881us/step - loss: 0.4167 - accuracy: 0.8791\n",
      "Epoch 932/1000\n",
      "1200/1200 [==============================] - 1s 832us/step - loss: 0.4170 - accuracy: 0.8804\n",
      "Epoch 933/1000\n",
      "1200/1200 [==============================] - 1s 850us/step - loss: 0.4160 - accuracy: 0.8797\n",
      "Epoch 934/1000\n",
      "1200/1200 [==============================] - 1s 840us/step - loss: 0.4183 - accuracy: 0.8782\n",
      "Epoch 935/1000\n",
      "1200/1200 [==============================] - 1s 860us/step - loss: 0.4157 - accuracy: 0.8787\n",
      "Epoch 936/1000\n",
      "1200/1200 [==============================] - 1s 831us/step - loss: 0.4166 - accuracy: 0.8809\n",
      "Epoch 937/1000\n",
      "1200/1200 [==============================] - 1s 847us/step - loss: 0.4182 - accuracy: 0.8800\n",
      "Epoch 938/1000\n",
      "1200/1200 [==============================] - 1s 833us/step - loss: 0.4174 - accuracy: 0.8793\n",
      "Epoch 939/1000\n",
      "1200/1200 [==============================] - 1s 855us/step - loss: 0.4181 - accuracy: 0.8794\n",
      "Epoch 940/1000\n",
      "1200/1200 [==============================] - 1s 830us/step - loss: 0.4152 - accuracy: 0.8786\n",
      "Epoch 941/1000\n",
      "1200/1200 [==============================] - 1s 856us/step - loss: 0.4170 - accuracy: 0.8799\n",
      "Epoch 942/1000\n",
      "1200/1200 [==============================] - 1s 832us/step - loss: 0.4174 - accuracy: 0.8798\n",
      "Epoch 943/1000\n",
      "1200/1200 [==============================] - 1s 861us/step - loss: 0.4176 - accuracy: 0.8792\n",
      "Epoch 944/1000\n",
      "1200/1200 [==============================] - 1s 827us/step - loss: 0.4196 - accuracy: 0.8794\n",
      "Epoch 945/1000\n",
      "1200/1200 [==============================] - 1s 855us/step - loss: 0.4190 - accuracy: 0.8795\n",
      "Epoch 946/1000\n",
      "1200/1200 [==============================] - 1s 827us/step - loss: 0.4170 - accuracy: 0.8798\n",
      "Epoch 947/1000\n",
      "1200/1200 [==============================] - 1s 815us/step - loss: 0.4186 - accuracy: 0.8790\n",
      "Epoch 948/1000\n",
      "1200/1200 [==============================] - 1s 797us/step - loss: 0.4188 - accuracy: 0.8790\n",
      "Epoch 949/1000\n",
      "1200/1200 [==============================] - 1s 809us/step - loss: 0.4174 - accuracy: 0.8805\n",
      "Epoch 950/1000\n",
      "1200/1200 [==============================] - 1s 796us/step - loss: 0.4182 - accuracy: 0.8787\n",
      "Epoch 951/1000\n",
      "1200/1200 [==============================] - 1s 784us/step - loss: 0.4165 - accuracy: 0.8795\n",
      "Epoch 952/1000\n",
      "1200/1200 [==============================] - 1s 811us/step - loss: 0.4180 - accuracy: 0.8792\n",
      "Epoch 953/1000\n",
      "1200/1200 [==============================] - 1s 796us/step - loss: 0.4185 - accuracy: 0.8807\n",
      "Epoch 954/1000\n",
      "1200/1200 [==============================] - 1s 818us/step - loss: 0.4181 - accuracy: 0.8788\n",
      "Epoch 955/1000\n",
      "1200/1200 [==============================] - 1s 794us/step - loss: 0.4181 - accuracy: 0.8792\n",
      "Epoch 956/1000\n",
      "1200/1200 [==============================] - 1s 806us/step - loss: 0.4184 - accuracy: 0.8798\n",
      "Epoch 957/1000\n",
      "1200/1200 [==============================] - 1s 795us/step - loss: 0.4160 - accuracy: 0.8789\n",
      "Epoch 958/1000\n",
      "1200/1200 [==============================] - 1s 806us/step - loss: 0.4180 - accuracy: 0.8784\n",
      "Epoch 959/1000\n",
      "1200/1200 [==============================] - 1s 803us/step - loss: 0.4167 - accuracy: 0.8805\n",
      "Epoch 960/1000\n",
      "1200/1200 [==============================] - 1s 804us/step - loss: 0.4176 - accuracy: 0.8775\n",
      "Epoch 961/1000\n",
      "1200/1200 [==============================] - 1s 799us/step - loss: 0.4168 - accuracy: 0.8792\n",
      "Epoch 962/1000\n",
      "1200/1200 [==============================] - 1s 810us/step - loss: 0.4189 - accuracy: 0.8783\n",
      "Epoch 963/1000\n",
      "1200/1200 [==============================] - 1s 802us/step - loss: 0.4194 - accuracy: 0.8787\n",
      "Epoch 964/1000\n",
      "1200/1200 [==============================] - 1s 832us/step - loss: 0.4178 - accuracy: 0.8788\n",
      "Epoch 965/1000\n",
      "1200/1200 [==============================] - 1s 807us/step - loss: 0.4179 - accuracy: 0.8804\n",
      "Epoch 966/1000\n",
      "1200/1200 [==============================] - 1s 816us/step - loss: 0.4169 - accuracy: 0.8786\n",
      "Epoch 967/1000\n",
      "1200/1200 [==============================] - 1s 793us/step - loss: 0.4190 - accuracy: 0.8782\n",
      "Epoch 968/1000\n",
      "1200/1200 [==============================] - 1s 832us/step - loss: 0.4197 - accuracy: 0.8808\n",
      "Epoch 969/1000\n",
      "1200/1200 [==============================] - 1s 793us/step - loss: 0.4184 - accuracy: 0.8790\n",
      "Epoch 970/1000\n",
      "1200/1200 [==============================] - 1s 824us/step - loss: 0.4176 - accuracy: 0.8800\n",
      "Epoch 971/1000\n",
      "1200/1200 [==============================] - 1s 797us/step - loss: 0.4184 - accuracy: 0.8782\n",
      "Epoch 972/1000\n",
      "1200/1200 [==============================] - 1s 819us/step - loss: 0.4180 - accuracy: 0.8788\n",
      "Epoch 973/1000\n",
      "1200/1200 [==============================] - 1s 792us/step - loss: 0.4183 - accuracy: 0.8790\n",
      "Epoch 974/1000\n",
      "1200/1200 [==============================] - 1s 813us/step - loss: 0.4183 - accuracy: 0.8790\n",
      "Epoch 975/1000\n",
      "1200/1200 [==============================] - 1s 799us/step - loss: 0.4184 - accuracy: 0.8798\n",
      "Epoch 976/1000\n",
      "1200/1200 [==============================] - 1s 811us/step - loss: 0.4180 - accuracy: 0.8790\n",
      "Epoch 977/1000\n",
      "1200/1200 [==============================] - 1s 803us/step - loss: 0.4165 - accuracy: 0.8795\n",
      "Epoch 978/1000\n",
      "1200/1200 [==============================] - 1s 807us/step - loss: 0.4188 - accuracy: 0.8791\n",
      "Epoch 979/1000\n",
      "1200/1200 [==============================] - 1s 796us/step - loss: 0.4186 - accuracy: 0.8807\n",
      "Epoch 980/1000\n",
      "1200/1200 [==============================] - 1s 810us/step - loss: 0.4178 - accuracy: 0.8798\n",
      "Epoch 981/1000\n",
      "1200/1200 [==============================] - 1s 796us/step - loss: 0.4188 - accuracy: 0.8806\n",
      "Epoch 982/1000\n",
      "1200/1200 [==============================] - 1s 808us/step - loss: 0.4191 - accuracy: 0.8810\n",
      "Epoch 983/1000\n",
      "1200/1200 [==============================] - 1s 788us/step - loss: 0.4179 - accuracy: 0.8805\n",
      "Epoch 984/1000\n",
      "1200/1200 [==============================] - 1s 797us/step - loss: 0.4190 - accuracy: 0.8789\n",
      "Epoch 985/1000\n",
      "1200/1200 [==============================] - 1s 799us/step - loss: 0.4197 - accuracy: 0.8788\n",
      "Epoch 986/1000\n",
      "1200/1200 [==============================] - 1s 801us/step - loss: 0.4184 - accuracy: 0.8794\n",
      "Epoch 987/1000\n",
      "1200/1200 [==============================] - 1s 806us/step - loss: 0.4194 - accuracy: 0.8791\n",
      "Epoch 988/1000\n",
      "1200/1200 [==============================] - 1s 792us/step - loss: 0.4208 - accuracy: 0.8785\n",
      "Epoch 989/1000\n",
      "1200/1200 [==============================] - 1s 813us/step - loss: 0.4215 - accuracy: 0.8791\n",
      "Epoch 990/1000\n",
      "1200/1200 [==============================] - 1s 798us/step - loss: 0.4203 - accuracy: 0.8807\n",
      "Epoch 991/1000\n",
      "1200/1200 [==============================] - 1s 827us/step - loss: 0.4189 - accuracy: 0.8795\n",
      "Epoch 992/1000\n",
      "1200/1200 [==============================] - 1s 796us/step - loss: 0.4195 - accuracy: 0.8784\n",
      "Epoch 993/1000\n",
      "1200/1200 [==============================] - 1s 817us/step - loss: 0.4190 - accuracy: 0.8786\n",
      "Epoch 994/1000\n",
      "1200/1200 [==============================] - 1s 792us/step - loss: 0.4201 - accuracy: 0.8795\n",
      "Epoch 995/1000\n",
      "1200/1200 [==============================] - 1s 822us/step - loss: 0.4209 - accuracy: 0.8799\n",
      "Epoch 996/1000\n",
      "1200/1200 [==============================] - 1s 794us/step - loss: 0.4195 - accuracy: 0.8815\n",
      "Epoch 997/1000\n",
      "1200/1200 [==============================] - 1s 824us/step - loss: 0.4194 - accuracy: 0.8808\n",
      "Epoch 998/1000\n",
      "1200/1200 [==============================] - 1s 793us/step - loss: 0.4199 - accuracy: 0.8794\n",
      "Epoch 999/1000\n",
      "1200/1200 [==============================] - 1s 807us/step - loss: 0.4200 - accuracy: 0.8792\n",
      "Epoch 1000/1000\n",
      "1200/1200 [==============================] - 1s 807us/step - loss: 0.4203 - accuracy: 0.8803\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2aa1f55ef50>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 훈련\n",
    "model.fit(train_scaled, train_target, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fa7a8af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 808us/step - loss: 1.0602 - accuracy: 0.8257\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.060200810432434, 0.8257291913032532]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(val_scaled, val_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03317084",
   "metadata": {},
   "source": [
    "|레이블|0|1|2|3|4|5|6|7|8|9|\n",
    "|:---|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\n",
    "|패션MIST|티셔츠|바지|스웨터|드레스|코트|샌달|셔츠|스티커즈|가방|앵클 부츠|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f095034f",
   "metadata": {},
   "source": [
    "#### 결론\n",
    "- `딥러닝` : 인공신경망. 생물학적 뉴런에서 영감을 받아 만든 머신러닝 알고리즘\n",
    "    - 이미지, 음성, 텍스트, 영상 분야에 뛰어난 성능 발휘\n",
    "- `밀집층` : Dense Laye. 가장 간단한 인공신경망\n",
    "- `원-핫 인코딩` : 해당 요소만 1로, 나머지는 0으로 변환하는 방식\n",
    "    - [1, 0, 0, 0, 0, 0, 0, 0] - 티셔츠\n",
    "    - [0, 0, 0, 0, 0, 1, 0, 0] - 스티커즈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff6320f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
